# BCOR 3750 Analytics Project Requirements
## Progressive Analytics Across the Maturity Scale

---

## Executive Summary

### Project Overview
This semester-long project is your opportunity to build a **portfolio-quality analytics case study** that demonstrates your ability to solve real operational problems using data. You will progress through all four analytics types—**Descriptive, Diagnostic, Predictive, and Prescriptive**—while building skills that directly transfer to professional roles in operations and supply chain management.

**Why This Matters for Your Career:**
- ✅ **Portfolio Piece**: Showcase this project in job interviews to demonstrate analytics capabilities
- ✅ **Real-World Skills**: Apply the exact tools and techniques used by operations analysts daily (Excel, Looker, forecasting, optimization)
- ✅ **Interview Practice**: The project interviews mirror actual job interview formats
- ✅ **Transferable Experience**: Based on a real job description you want to pursue

### Project Weight
- **Total**: 45% of your final grade (15 points per milestone)
- **Milestone 1** (Descriptive + Diagnostic): 15 points - Due **Monday, October 13, 2025**
- **Milestone 2** (Predictive): 15 points - Due **Tuesday, November 4, 2025**
- **Milestone 3** (Prescriptive): 15 points - Due **Thursday, December 4, 2025**

### Core Frameworks
Throughout this project, you will apply:

**DC ACT Framework (5-Step Analytics Process)**
1. **Define** the business problem
2. **Collect** and prepare the data
3. **Analyze** the data and generate insights
4. **Communicate** the insights, recommendations, and predictions
5. **Act** and track the change

**Data Quality Framework**
1. **Identify** the data quality issue
2. **Assess** the business ramification
3. **Analyze** the root cause
4. **Decide** on the best option (Remove / Update / Do Nothing)
5. **Fix** the issue, if applicable

**10 Operations Management Decision Areas**
1. Design of Goods & Services
2. Quality Management
3. Process & Capacity Design
4. Location Strategy
5. Layout Strategy
6. Human Resources & Job Design
7. Supply Chain Management
8. Inventory Management
9. Scheduling
10. Maintenance

---

## Part 1: Project Foundation (Complete by Week 4)

### 1.1 Job Description Selection

**Requirement**: Find and save a **real, currently posted job** in operations or supply chain management that you can realistically see yourself pursuing.

**Specifications:**
- **Career Level**: Entry-level positions (analyst, coordinator, specialist roles)
- **Industry**: Any industry, but job must be related to operations/supply chain management in some way
- **Company**: Must be a real, operating company
- **Justification**: Be prepared to explain how this role connects to ops/SCM

**Action Items:**
1. Search job boards (LinkedIn, Indeed, company career sites) for relevant positions
2. Select ONE job that interests you and aligns with your career goals
3. **Save the complete job posting as a PDF** (in case the posting is removed later)
4. Review the job description to identify:
   - Key responsibilities related to data and analytics
   - Metrics or KPIs mentioned
   - Operational challenges the role addresses
   - Tools or systems mentioned

**Why Save as PDF?** Job postings often expire. You'll be able to reference this for future applications and can adapt your project to similar roles even if this specific job is no longer available.

---

### 1.2 Operations Management Decision Area Selection

**Requirement**: Select ONE primary Operations Management Decision Area that aligns with your job description and will be the focus of your entire project.

**The 10 Decision Areas:**
1. **Design of Goods & Services**: What product or service are we creating, and who is it for?
2. **Quality Management**: How do we meet expectations every time?
3. **Process & Capacity Design**: How will the work get done, and how much can we produce?
4. **Location Strategy**: Where should we set up to serve customers best?
5. **Layout Strategy**: How do we arrange people, machines, or space for smooth flow?
6. **Human Resources & Job Design**: Who does the work, and how do we design jobs people want to do?
7. **Supply Chain Management**: Where do our materials come from, and how do products reach customers?
8. **Inventory Management**: How much should we keep in stock, and when should we restock?
9. **Scheduling**: When should people, machines, and tasks be assigned?
10. **Maintenance**: How do we keep everything running reliably over time?

**Action Items:**
1. Review your job description and identify which decision area(s) it addresses
2. Select ONE primary decision area as your project focus
3. Write 2-3 sentences justifying your selection based on the job responsibilities

**Example:**
> "I selected **Supply Chain Management** as my decision area because the Supply Chain Analyst role at Amazon focuses on optimizing order fulfillment and delivery performance. The job description mentions analyzing delivery times, carrier performance, and distribution network efficiency—all core supply chain decisions."

---

### 1.3 Stakeholder Identification

**Requirement**: Identify a **specific stakeholder** who would benefit from your analysis. This should be a real person (when possible) with the job title and responsibilities described in your target role.

**Specifications:**
- **Job Title**: Specific title from job posting or related role (e.g., "Warehouse Operations Manager" not just "Manager")
- **Department**: Which department does this person work in?
- **Responsibilities**: What are their main operational responsibilities?
- **LinkedIn Research**: Find a real person on LinkedIn with this role at your target company (or similar company) and include their LinkedIn profile URL

**Why LinkedIn Research?**
- Makes your project feel like a real consulting engagement
- Helps you understand what the role actually does
- Prepares you for networking and informational interviews
- Adds authenticity when discussing this project in job interviews

**Action Items:**
1. Identify the stakeholder title from your job description
2. Research this role on LinkedIn at your target company
3. Document:
   - Stakeholder name (if found)
   - Job title
   - Company
   - LinkedIn profile URL
   - 2-3 key responsibilities related to your analysis

---

### 1.4 Problem Statement Development

**Requirement**: Define a clear, specific business problem that your stakeholder needs to solve using data. This problem will guide ALL your analytics work.

**Problem Statement Template:**
> "[Stakeholder] at [Company] is facing [specific challenge] which is causing [business impact]. Currently, [what's not working well]. Success would look like [desired outcome]."

**Examples by Decision Area:**

**Supply Chain Management:**
> "The Fulfillment Operations Manager at ShopNow is facing increasing delivery times (average 5.2 days vs. target of 3 days) which is causing customer complaints to rise 40% quarter-over-quarter. Currently, they don't understand which factors (carrier, region, warehouse location) are driving delays. Success would look like identifying root causes and reducing delivery times back to 3-day target."

**Inventory Management:**
> "The Inventory Analyst at TechParts Inc. is facing high carrying costs ($2M annually, 30% above industry benchmark) combined with frequent stockouts (15% of SKUs out of stock weekly). Currently, they use fixed reorder points that don't account for demand variability. Success would look like optimizing reorder points to reduce carrying costs by 20% while maintaining 95% in-stock rate."

**Process & Capacity Design:**
> "The Production Planning Manager at AutoSupply Manufacturing is facing unpredictable production output (ranging from 200-400 units daily) which is causing missed customer order deadlines. Currently, they can't forecast production capacity accurately due to variable cycle times. Success would look like predicting daily production capacity within ±10% to improve order promising accuracy."

**Quality Management:**
> "The Quality Manager at FoodCo is facing increasing defect rates (currently 4.2% vs. target of 2%) which is causing customer returns and warranty costs to increase. Currently, they don't know which production factors (shift, line, supplier batch) correlate with defects. Success would look like identifying root causes and implementing controls to achieve 2% defect target."

**Action Items:**
1. Draft your problem statement using the template
2. Ensure it includes:
   - Specific stakeholder and company
   - Measurable challenge (with numbers if possible)
   - Business impact (why this matters)
   - Current state (what's not working)
   - Desired outcome (what success looks like)
3. Validate that this problem can be analyzed with data

---

### 1.5 Project Kickoff Checklist

**Complete this checklist by Week 4** to ensure you have a solid foundation:

- [ ] Job posting saved as PDF
- [ ] Job title and company documented
- [ ] Operations Management Decision Area selected and justified
- [ ] Stakeholder identified (name, title, LinkedIn URL if possible)
- [ ] Problem statement drafted (includes challenge, impact, current state, desired outcome)
- [ ] Problem connects clearly to Decision Area
- [ ] Problem can be analyzed using data

**Recommendation**: Schedule office hours in Week 3-4 to review your foundation before data collection begins.

---

## Part 2: Data Collection & Quality (All Milestones)

### 2.1 Data Sources

You have **two options** for data collection:

#### Option 1: Custom GPT Data Generator (Recommended)
Use the **Data Craft Custom GPT** to generate realistic synthetic operational data tailored to your specific problem.

**Advantages:**
- Generates data specifically designed for your job/problem/decision area
- Includes intentional data quality issues for learning
- Creates data structured for all four analytics types
- Provides data dictionary and analysis guidance

**How to Use:**
1. Access Data Craft Custom GPT [link will be provided in Brightspace]
2. Upload your resume and job description PDF
3. Answer questions ONE AT A TIME as the GPT guides you
4. The GPT will generate customized datasets with documentation
5. Review the "How to Use Data Craft GPT" guide [link in Brightspace]

#### Option 2: Bring Your Own Data
Collect data from public sources, Kaggle, company internships (with permission), or other legitimate sources.

**Requirements if using your own data:**
- **Minimum size**: 500 rows, 5+ variables
- **Data quality**: Must include realistic data quality issues (if your data is perfect, you must artificially introduce issues for the learning exercise)
- **Relevance**: Data must directly relate to your job description, decision area, and problem statement
- **Documentation**: Create your own data dictionary explaining all fields

**Acceptable Sources:**
- Public datasets (government data, industry benchmarks)
- Kaggle datasets (with proper attribution)
- Company data from internships/jobs (with explicit permission and anonymization)
- Academic datasets from reputable sources

---

### 2.2 Data Relevance

Your data must be relevant to your project through AT LEAST ONE of these connections:

1. **Job Function**: Data directly relates to the responsibilities in your job description
   - Example: Job is "Logistics Analyst" → Data is shipment/delivery data

2. **Company**: Data comes from or represents your target company's industry
   - Example: Job is at Amazon → Data is e-commerce order fulfillment data

3. **Industry**: Data represents typical operations in your target industry
   - Example: Job is in healthcare supply chain → Data is hospital inventory/patient flow data

**You may use different datasets for different analytics types:**
- **Descriptive + Diagnostic**: MUST use the same dataset (you're analyzing what happened and why)
- **Predictive**: Can use the same dataset as Descriptive/Diagnostic OR a different dataset if needed
- **Prescriptive**: Can use the same dataset OR a different dataset if the original doesn't support optimization/simulation

**Why allow different datasets?**
Sometimes your descriptive/diagnostic dataset doesn't have the right structure for time series forecasting or optimization. It's better to use appropriate data than to force the wrong data into an analysis technique.

---

### 2.3 Data Quality Assessment (Required for Milestone 1)

**Requirement**: Use the **Data Quality Framework** to identify, assess, and fix data quality issues.

**Data Quality Framework:**
1. **Identify** the data quality issue (what type of issue is it?)
2. **Assess** the business ramification (why does this matter?)
3. **Analyze** the root cause (why did this issue occur?)
4. **Decide** on the best option (Remove / Update / Do Nothing)
5. **Fix** the issue, if applicable (implement your decision)

**Data Quality Dimensions** (from course framework):
- **Availability**: Is the data accessible when needed?
- **Accuracy**: Is the data correct and free from errors?
- **Completeness**: Are all required data points present?
- **Consistency**: Is the data uniform across sources/fields?
- **Validity**: Does the data conform to business rules?
- **Uniqueness**: Are there duplicate records?
- **Timeliness**: Is the data current and up-to-date?

**Minimum Requirements:**
- Identify and document **at least 3 different types** of data quality issues
- For EACH issue, complete all 5 framework steps
- Fix critical issues that would impact analysis accuracy
- Document issues you chose NOT to fix and explain why

**Common Data Quality Issues:**
- **Missing Values**: 2-5% of records with null/blank cells
- **Duplicate Records**: 1-3% exact or near-duplicate entries
- **Date Format Inconsistencies**: Mix of YYYY-MM-DD, MM/DD/YYYY, or other formats
- **Outliers**: Values that are statistically anomalous but may be valid
- **Inconsistent Categories**: Variations like "Northeast", "North East", "NE"

**Deliverable**: Create a **Data Quality Assessment Document** with this structure:

```
Data Quality Assessment Report

Issue #1: [Type of Issue]
1. Identify: [Description of the issue, which fields affected, how many records]
2. Assess: [Business impact - how does this affect analysis or decisions?]
3. Analyze: [Root cause - why did this issue occur?]
4. Decide: [Your decision - Remove / Update / Do Nothing]
5. Fix: [What you did to fix it, or why you chose not to fix]

Issue #2: [Type of Issue]
[Repeat framework...]

Issue #3: [Type of Issue]
[Repeat framework...]

Summary:
- Total records in original dataset: [X]
- Total records after cleaning: [X]
- Records removed: [X] ([X]%)
- Records updated: [X] ([X]%)
- Issues identified but not fixed: [X] (with justification)
```

---

### 2.4 Data Requirements by Analytics Type

#### Descriptive Analytics (Milestone 1)
**Data Structure Needed:**
- Time-stamped data (dates for trend analysis)
- Numeric metrics (for summary statistics)
- Categorical dimensions (for grouping and comparisons)
- Minimum 6 months of data recommended (for meaningful trends)

**Example Fields:**
- Date/timestamp, transaction ID, metric values (revenue, quantity, time), categories (region, product, customer segment)

---

#### Diagnostic Analytics (Milestone 1)
**Data Structure Needed:**
- Same dataset as Descriptive
- Multiple categorical dimensions for drilling down
- Sufficient granularity to identify patterns

**Example Fields:**
- All fields from Descriptive, PLUS dimensions for root cause analysis (warehouse location, shift, day of week, product category, etc.)

---

#### Predictive Analytics (Milestone 2)

**For Time Series Forecasting:**
- Sequential time-stamped data with NO GAPS (daily, weekly, or monthly)
- At least 12-24 months of historical data
- Clear trends or seasonal patterns
- Target variable to forecast (demand, delivery time, defect rate, etc.)

**Example Fields:**
- Date (sequential), target_metric (what you're forecasting), optional: external factors (marketing spend, weather, holidays)

**For Regression Analysis:**
- 500-1000 records minimum
- Dependent variable (what you're predicting)
- 3-8 independent variables (factors that influence the dependent variable)
- Mix of continuous and categorical variables

**Example Fields:**
- Record ID, dependent_variable (delivery time), independent_variables (distance, weight, carrier, weather, is_express, etc.)

---

#### Prescriptive Analytics (Milestone 3)

**For Linear Programming (Optimization):**
- Decision variables (what you're deciding: product quantities, resource allocations, etc.)
- Objective function coefficients (profit per unit, cost per unit, etc.)
- Constraint parameters (budget limits, capacity limits, minimum requirements)
- 3-10 decision variables recommended

**Example Structure:**
- Decision variables table (products with profit/cost per unit)
- Constraints table (budget, capacity, minimum/maximum limits)
- Resource usage matrix (how much of each resource each decision uses)

**For Monte Carlo Simulation:**
- Historical data showing variability (250-500 records)
- Uncertain variables (demand, lead time, defect rate, etc.)
- Probability distributions (mean, standard deviation, min, max)

**Example Structure:**
- Historical variability data (showing past values of uncertain variables)
- Distribution parameters table (mean, std dev, min, max for each uncertain variable)

---

## Part 3: Milestone Requirements

### Milestone 1: Descriptive & Diagnostic Analytics
**Due: Monday, October 13, 2025 by 11:59 PM**
**Weight: 15 points**

#### What You're Answering:
- **Descriptive**: "What happened?" - Summary, trends, patterns
- **Diagnostic**: "Why did it happen?" - Root cause analysis

#### Technical Requirements

**Excel Analysis:**
- **Descriptive**: Pivot tables, summary statistics (mean, median, mode, std dev), data profiling
- **Diagnostic**: Pivot tables with slicers for drilling down into root causes

**Looker Dashboard #1: Strategic Dashboard (Descriptive)**
- **Purpose**: High-level view of what happened
- **Required Components**:
  - Minimum 1 control (date range selector OR filter)
  - 1 scorecard showing KPI with comparison (vs. previous period OR vs. target)
  - 1 line chart (showing trend over time)
  - 1 bar chart (showing comparison across categories)
  - Additional charts/visuals are welcome

**Looker Dashboard #2: Operational Dashboard (Diagnostic)**
- **Purpose**: Detailed view for root cause analysis
- **Required Components**:
  - Minimum 1 control (date range selector OR filter)
  - 1 scorecard showing KPI with comparison
  - 1 line chart (drilling into time-based patterns)
  - 1 bar chart (comparing across dimensions)
  - Additional charts/visuals are welcome
- **Note**: This should be a separate page/tab in the same Looker report, not a completely separate report

#### Deliverables (DC ACT Framework)

**1. Define**
- Problem statement (from Part 1.4)
- Stakeholder identification (from Part 1.3)
- Operations Management Decision Area (from Part 1.2)

**2. Collect**
- Data Quality Assessment Report (using framework from Part 2.3)
- Original data file (before cleaning)
- Cleaned data file (after quality improvements)
- Data dictionary

**3. Analyze**
- Excel workbook with:
  - Data cleaning tab
  - Descriptive analysis tab (pivot tables, summary statistics)
  - Diagnostic analysis tab (root cause pivot tables with slicers)
  - Clear labels and formatting
- Looker dashboard links:
  - Strategic Dashboard (Descriptive)
  - Operational Dashboard (Diagnostic)

**4. Communicate**
- **Slide Deck** (3-5 slides covering both Descriptive AND Diagnostic):
  - **Slide 1**: Project overview (job, stakeholder, problem, decision area)
  - **Slides 2-3**: Descriptive insights with **takeaway titles** (what happened?)
  - **Slides 4-5**: Diagnostic insights with **takeaway titles** (why did it happen?)
  - Each slide must have:
    - Takeaway title (the insight, not a description)
    - Supporting visual (chart, table, or screenshot from Excel/Looker)
    - 2-3 bullet points of interpretation

**5. Act**
- Recommendations based on your root cause findings
- Specific actions for your stakeholder to take
- How to track improvement (what metrics to monitor)

#### Submission Files
Upload to Brightspace by **Monday, October 13, 2025, 11:59 PM**:

1. `[LastName]_[FirstName]_Milestone1_Slides.pptx` or `.pdf`
2. `[LastName]_[FirstName]_Milestone1_DataQuality.pdf`
3. `[LastName]_[FirstName]_Milestone1_OriginalData.csv`
4. `[LastName]_[FirstName]_Milestone1_CleanedData.csv`
5. `[LastName]_[FirstName]_Milestone1_Analysis.xlsx`
6. `[LastName]_[FirstName]_Milestone1_LookerLinks.pdf` (document with dashboard URLs)
7. `[LastName]_[FirstName]_JobPosting.pdf` (your saved job description)

---

### Milestone 2: Predictive Analytics
**Due: Tuesday, November 4, 2025 by 11:59 PM**
**Weight: 15 points**

#### What You're Answering:
- **Predictive**: "What will happen?" - Forecasting and prediction

#### Technical Requirements

**Time Series Forecasting (Excel):**
You must apply BOTH methods and compare results:

1. **Moving Average**
   - 3-month (or 3-week/3-day depending on granularity)
   - 6-month (or 6-week/6-day)
   - Calculate forecast accuracy (MAPE or RMSE)

2. **Exponential Smoothing**
   - Alpha = 0.2 (slow response to changes)
   - Alpha = 0.5 (moderate response)
   - Calculate forecast accuracy (MAPE or RMSE)

**Comparison Required:**
- Create a table comparing all methods' accuracy
- Select the BEST method and justify your choice
- Generate forecast for next period using your selected method

**Multiple Linear Regression (Excel):**
- Dependent variable: What you're predicting
- Independent variables: 3-8 factors that influence the dependent variable
- Use Excel Data Analysis Toolpak for regression
- **Interpret Key Outputs**:
  - Adjusted R² (how well the model fits)
  - Coefficients (relationship between each independent variable and dependent variable)
  - P-values (statistical significance)
  - Y-intercept (baseline prediction)
- Make predictions for new scenarios using your model
- Discuss business implications of the relationships you found

#### Deliverables (DC ACT Framework)

**1. Define**
- What are you trying to predict and why?
- How does this prediction help your stakeholder make better decisions?
- Time horizon for forecast (next week? month? quarter?)

**2. Collect**
- If using new dataset: Data Quality Assessment
- If using same dataset: Explain why it's suitable for forecasting/regression
- Data dictionary

**3. Analyze**
- Excel workbook with:
  - Time Series Forecasting tab (both methods, comparison, selected forecast)
  - Regression Analysis tab (model output, interpretation, predictions)
  - Clear labels, formulas visible, professional formatting
- **Show your work**: Don't just paste regression output—annotate what it means

**4. Communicate**
- **Slide Deck** (3-5 NEW slides added to your existing deck):
  - **Slide 1**: Forecasting problem and approach
  - **Slide 2**: Time series results with **takeaway title** (which method works best? what's the forecast?)
  - **Slide 3**: Regression results with **takeaway title** (what relationships drive predictions?)
  - **Slide 4-5**: Business implications and how stakeholder should use these predictions
  - Each slide must have:
    - Takeaway title (the insight, not "Regression Analysis")
    - Supporting visual (chart showing forecast, regression coefficients, etc.)
    - Interpretation of what this means for the business

**5. Act**
- How should your stakeholder use these predictions?
- What decisions can be made with this forecast?
- What are the risks/limitations of the predictions?
- How to monitor actual vs. predicted (track prediction accuracy)

#### Submission Files
Upload to Brightspace by **Tuesday, November 4, 2025, 11:59 PM**:

1. `[LastName]_[FirstName]_Milestone2_Slides.pptx` or `.pdf` (cumulative deck with Milestone 1 + 2 slides)
2. `[LastName]_[FirstName]_Milestone2_Analysis.xlsx` (forecasting + regression)
3. `[LastName]_[FirstName]_Milestone2_Data.csv` (if using new dataset)
4. `[LastName]_[FirstName]_Milestone2_DataQuality.pdf` (if using new dataset)

---

### Milestone 3: Prescriptive Analytics
**Due: Thursday, December 4, 2025 by 11:59 PM**
**Weight: 15 points**

#### What You're Answering:
- **Prescriptive**: "What should we do?" - Optimization and simulation for decision-making

#### Technical Requirements

You must complete BOTH analyses (or justify why only one applies):

**1. Linear Programming with Excel Solver**

**Setup:**
- **Decision Variables**: 3-10 variables representing choices (how much to produce? how to allocate resources?)
- **Objective Function**: What are you maximizing or minimizing? (profit, cost, throughput, etc.)
- **Constraints**: 4-8 limitations (budget, capacity, time, minimum/maximum requirements)

**Analysis:**
- Build optimization model in Excel
- Use Solver to find optimal solution
- Run sensitivity analysis (what happens if constraints change?)
- Interpret results in business terms

**Example Problem Types:**
- Production planning: How many units of each product to produce?
- Resource allocation: How to allocate warehouse space to maximize profit?
- Transportation: Which routes/carriers to use to minimize cost?
- Inventory: What reorder quantities minimize total inventory costs?

---

**2. Monte Carlo Simulation (Excel)**

**Setup:**
- **Uncertain Variable(s)**: What has variability? (demand, lead time, defect rate, costs)
- **Probability Distribution**: Normal, uniform, or triangular distribution with parameters
- **Simulation**: Run 1,000-10,000 scenarios using Excel's random number functions

**Analysis:**
- Model the uncertain process in Excel
- Generate random values based on probability distribution
- Calculate outcome for each simulation run
- Analyze distribution of outcomes (mean, standard deviation, percentiles)
- Determine probabilities and confidence intervals

**Example Problem Types:**
- Inventory risk: What's the probability of stockout given variable demand and lead times?
- Capacity planning: How much capacity needed to meet demand 95% of the time?
- Quality: What's expected defect rate given variable process performance?
- Financial: What's the range of possible costs/revenues given variable inputs?

---

**Basic Complexity Guidance:**
This is your first exposure to these advanced techniques. We expect:
- **Linear Programming**: Basic problem with 3-6 decision variables, 4-6 constraints
- **Simulation**: Single uncertain variable with clear probability distribution
- **Focus**: Correct application of technique and business interpretation, not mathematical sophistication

---

#### Deliverables (DC ACT Framework)

**1. Define**
- What decision is your stakeholder trying to make?
- What are they trying to optimize or understand uncertainty around?
- Why does this require prescriptive analytics (not just prediction)?

**2. Collect**
- Data for optimization parameters (costs, profits, capacities, limits)
- Historical data showing variability for simulation
- If using new dataset: Data Quality Assessment
- Data dictionary

**3. Analyze**
- Excel workbook with:
  - **Linear Programming tab**:
    - Decision variables clearly labeled
    - Objective function formula
    - Constraint formulas
    - Solver setup and solution
    - Sensitivity analysis results
  - **Monte Carlo Simulation tab**:
    - Random number generation formulas
    - Simulation model (1,000-10,000 runs)
    - Distribution of outcomes
    - Statistical summary (mean, std dev, percentiles)
    - Probability calculations
  - Clear documentation of assumptions, formulas, and results

**4. Communicate**
- **Slide Deck** (3-5 NEW slides added to your cumulative deck):
  - **Slide 1**: Prescriptive problem and approach
  - **Slide 2**: Optimization results with **takeaway title** (what's the optimal solution?)
  - **Slide 3**: Simulation results with **takeaway title** (what's the probability distribution? risk assessment?)
  - **Slide 4-5**: Decision recommendations and implementation roadmap
  - Each slide must have:
    - Takeaway title (the actionable insight)
    - Supporting visual (optimal solution table, probability distribution chart, etc.)
    - Interpretation of what stakeholder should do

**5. Act**
- **Specific Recommendations**: Based on optimization, what should stakeholder do?
- **Risk Assessment**: Based on simulation, what are the risks and how to mitigate?
- **Implementation Plan**: Steps to implement optimal solution
- **Monitoring Plan**: How to track if optimization is working, when to re-optimize

---

#### Submission Files
Upload to Brightspace by **Thursday, December 4, 2025, 11:59 PM**:

1. `[LastName]_[FirstName]_Milestone3_Slides.pptx` or `.pdf` (COMPLETE cumulative deck with all milestones)
2. `[LastName]_[FirstName]_Milestone3_Analysis.xlsx` (optimization + simulation)
3. `[LastName]_[FirstName]_Milestone3_Data.csv` (if using new dataset)
4. `[LastName]_[FirstName]_Milestone3_DataQuality.pdf` (if using new dataset)

---

## Part 4: Grading Rubrics

### Grading Breakdown per Milestone (15 points each)

Each milestone is graded on:
- **Technical Execution**: 10.5 points (70%)
- **Presentation Clarity**: 4.5 points (30%)

**Technical Execution Breakdown (10.5 points):**
- Data Quality & Preparation: 2 points
- Technical Analysis Execution: 4 points
- Business Insights & Interpretation: 2.5 points
- Recommendations & Actions: 2 points

**Presentation Clarity Breakdown (4.5 points):**
- Slide design and visual quality: 1.5 points
- Takeaway titles and messaging: 1.5 points
- Professional communication: 1.5 points

---

### Milestone 1: Descriptive & Diagnostic Analytics Rubric (15 points)

#### Data Quality & Preparation (2 points)
- **2.0 - Excellent**: Identified 3+ quality issues, applied framework thoroughly for each, fixed critical issues appropriately, clear documentation
- **1.5 - Good**: Identified 2-3 issues, applied framework adequately, fixed most issues, adequate documentation
- **1.0 - Adequate**: Identified 1-2 issues, framework applied incompletely, some issues fixed, minimal documentation
- **0.5 - Poor**: Minimal issue identification, framework not applied, little to no fixing, inadequate documentation
- **0 - Missing**: No data quality assessment

#### Technical Analysis Execution (4 points)
- **4.0 - Excellent**:
  - Excel: Correct pivot tables, comprehensive summary statistics, professional formatting
  - Looker: Both dashboards meet all requirements, visuals are clear and insightful, controls work properly
  - Analysis reveals non-obvious patterns
- **3.0 - Good**:
  - Excel: Correct pivot tables, adequate summary statistics, good formatting
  - Looker: Both dashboards meet minimum requirements, visuals are adequate, controls functional
  - Analysis shows expected patterns
- **2.0 - Adequate**:
  - Excel: Basic pivot tables, limited summary statistics, acceptable formatting
  - Looker: Dashboards meet most requirements, some visuals unclear, controls present
  - Analysis is surface-level
- **1.0 - Poor**:
  - Excel: Incorrect or incomplete analysis, poor formatting
  - Looker: Missing required components, visuals unclear, controls missing/broken
  - Analysis is superficial or incorrect
- **0 - Missing**: No technical analysis

#### Business Insights & Interpretation (2.5 points)
- **2.5 - Excellent**: Insights are business-relevant, actionable, reveal root causes, connect clearly to decision area
- **2.0 - Good**: Insights are relevant, somewhat actionable, identify some root causes, connect to decision area
- **1.5 - Adequate**: Insights are generic, limited actionability, surface-level root cause analysis
- **1.0 - Poor**: Insights are obvious or irrelevant, no clear root cause identification
- **0 - Missing**: No insights provided

#### Recommendations & Actions (2 points)
- **2.0 - Excellent**: Specific actions for stakeholder, clear implementation steps, metrics to track improvement
- **1.5 - Good**: Clear recommendations, general implementation guidance, some tracking metrics
- **1.0 - Adequate**: Generic recommendations, vague implementation, limited tracking
- **0.5 - Poor**: Obvious or irrelevant recommendations, no implementation guidance
- **0 - Missing**: No recommendations

#### Presentation Clarity (4.5 points)
- **4.5 - Excellent**: Professional design, compelling takeaway titles, clear visuals supporting insights, polished communication
- **3.5 - Good**: Good design, adequate takeaway titles, visuals support insights, clear communication
- **2.5 - Adequate**: Basic design, some takeaway titles, visuals present but not optimized, adequate communication
- **1.5 - Poor**: Poor design, descriptive titles (not takeaways), unclear visuals, weak communication
- **0 - Missing**: No slides or severely inadequate presentation

---

### Milestone 2: Predictive Analytics Rubric (15 points)

#### Data Quality & Preparation (2 points)
- **If new dataset**: Same rubric as Milestone 1
- **If same dataset**: 2 points for explaining suitability for forecasting/regression

#### Technical Analysis Execution (4 points)
- **4.0 - Excellent**:
  - Time Series: Both methods applied correctly, accurate forecast, valid comparison, best method selected with justification
  - Regression: Correct model, all key outputs interpreted correctly (R², coefficients, p-values), valid predictions
  - Formulas and work shown clearly
- **3.0 - Good**:
  - Time Series: Both methods applied, forecast generated, comparison adequate, method selection reasonable
  - Regression: Correct model, most outputs interpreted, predictions made
  - Work mostly clear
- **2.0 - Adequate**:
  - Time Series: One or both methods applied with minor errors, forecast generated, limited comparison
  - Regression: Model built but interpretation incomplete, predictions attempted
  - Work somewhat unclear
- **1.0 - Poor**:
  - Time Series: Significant errors in methods, forecast questionable, no comparison
  - Regression: Model incorrect or interpretation missing, predictions invalid
  - Work unclear or missing
- **0 - Missing**: No technical analysis

#### Business Insights & Interpretation (2.5 points)
- **2.5 - Excellent**: Insights explain what predictions mean for business, clear implications, connects to decision-making
- **2.0 - Good**: Insights relate predictions to business, general implications, some connection to decisions
- **1.5 - Adequate**: Generic insights, limited business relevance, weak connection to decisions
- **1.0 - Poor**: No clear business insights, just technical results
- **0 - Missing**: No insights

#### Recommendations & Actions (2 points)
- **2.0 - Excellent**: Specific guidance on how to use predictions, decision framework, risk/limitation discussion, monitoring plan
- **1.5 - Good**: Clear guidance on using predictions, some decision support, mentions limitations, basic monitoring
- **1.0 - Adequate**: General recommendations, limited decision support, minimal limitation discussion
- **0.5 - Poor**: Vague recommendations, no decision support
- **0 - Missing**: No recommendations

#### Presentation Clarity (4.5 points)
Same rubric as Milestone 1

---

### Milestone 3: Prescriptive Analytics Rubric (15 points)

#### Data Quality & Preparation (2 points)
- **If new dataset**: Same rubric as Milestone 1
- **If same dataset**: 2 points for explaining suitability for optimization/simulation

#### Technical Analysis Execution (4 points)
- **4.0 - Excellent**:
  - Linear Programming: Correct model setup, valid constraints, Solver used correctly, optimal solution found, sensitivity analysis completed
  - Simulation: Correct probability distributions, 1000+ runs, distribution analyzed correctly, probabilities calculated
  - Both analyses completed (or one justified thoroughly)
- **3.0 - Good**:
  - Linear Programming: Model mostly correct, Solver used, solution found, limited sensitivity analysis
  - Simulation: Correct approach, adequate runs, basic distribution analysis
  - Both analyses attempted
- **2.0 - Adequate**:
  - Linear Programming: Model setup with errors, Solver used, solution questionable
  - Simulation: Basic approach, limited runs, incomplete analysis
  - One or both analyses incomplete
- **1.0 - Poor**:
  - Significant errors in setup or execution
  - Only one analysis attempted with major issues
- **0 - Missing**: No technical analysis

#### Business Insights & Interpretation (2.5 points)
- **2.5 - Excellent**: Insights explain optimal solution/risk profile in business terms, clear decision implications, connects to decision area
- **2.0 - Good**: Insights relate results to business, general implications, some decision guidance
- **1.5 - Adequate**: Generic insights, limited business relevance
- **1.0 - Poor**: No clear business insights, just technical results
- **0 - Missing**: No insights

#### Recommendations & Actions (2 points)
- **2.0 - Excellent**: Specific implementation plan for optimal solution, risk mitigation strategies, monitoring and re-optimization plan
- **1.5 - Good**: Clear implementation guidance, some risk discussion, basic monitoring plan
- **1.0 - Adequate**: General recommendations, limited implementation detail
- **0.5 - Poor**: Vague recommendations, no implementation plan
- **0 - Missing**: No recommendations

#### Presentation Clarity (4.5 points)
Same rubric as Milestone 1

---

## Part 5: Presentation & Communication Guidelines

### Slide Deck Requirements

**Cumulative Structure:**
Your slide deck grows throughout the semester:
- After Milestone 1: 3-5 slides
- After Milestone 2: 6-10 slides (Milestone 1 + 2)
- After Milestone 3: 9-15 slides (complete project)

**Required Sections in Final Deck:**
1. **Project Overview** (1 slide)
   - Job description and company
   - Stakeholder
   - Operations Management Decision Area
   - Problem statement

2. **Data Quality** (1 slide)
   - Key data quality issues identified and fixed
   - Impact on analysis

3. **Descriptive Analytics** (1-2 slides)
   - What happened?
   - Key trends and patterns
   - Screenshots from Looker or Excel

4. **Diagnostic Analytics** (1-2 slides)
   - Why did it happen?
   - Root cause findings
   - Screenshots from Looker or Excel

5. **Predictive Analytics** (1-2 slides)
   - What will happen?
   - Forecast results and model interpretation
   - Charts showing forecasts and regression

6. **Prescriptive Analytics** (1-2 slides)
   - What should we do?
   - Optimal solution and risk assessment
   - Optimization results and simulation distributions

7. **Recommendations & Actions** (1-2 slides)
   - Specific actions for stakeholder
   - Implementation roadmap
   - How to track success

---

### Takeaway Slide Titles (Critical!)

**What are takeaway titles?**
Takeaway titles communicate YOUR INSIGHT, not what the slide is about.

**❌ POOR Titles (Descriptive):**
- "Delivery Time Analysis"
- "Sales by Region"
- "Regression Results"
- "Simulation Output"

**✅ EXCELLENT Titles (Takeaway):**
- "Delivery Times Increased 40% in Q3 Due to Western Region Warehouse Delays"
- "Northeast Region Drives 60% of Revenue Despite Representing Only 30% of Customers"
- "Package Weight and Distance Explain 78% of Delivery Time Variation"
- "95% Probability of Stockout with Current Inventory Policy"

**Formula for Takeaway Titles:**
[Metric] + [Direction/Magnitude] + [Key Driver/Implication]

**Examples by Analytics Type:**

**Descriptive:**
> "Order Volume Grew 25% Year-Over-Year with December Peak at 2X Average"

**Diagnostic:**
> "Late Deliveries Concentrated in Weekend Orders from Warehouse B"

**Predictive:**
> "Demand Forecast Shows 15% Growth Next Quarter Driven by Seasonal Trends"

**Prescriptive:**
> "Optimal Product Mix Increases Profit by $45K Monthly Within Current Constraints"

---

### Visual Requirements

**Every slide needs a supporting visual:**
- **Charts**: Bar charts, line charts, scatter plots from Excel or Looker
- **Tables**: Formatted tables highlighting key numbers
- **Screenshots**: Dashboards from Looker, Solver solutions, simulation results
- **Diagrams**: Process flows, decision trees (if relevant)

**Chart Best Practices:**
- Clear axis labels with units
- Legends when needed
- Highlight key data points
- Remove chartjunk (unnecessary 3D effects, gridlines, etc.)
- Use consistent color scheme throughout deck

**Reference Tools:**
- Include links to Looker dashboards in appendix or notes
- Mention "See Excel file for detailed calculations"
- Don't make readers guess where analysis lives

---

### Professional Communication Standards

**What "Professional" Means:**
- ✅ Consistent formatting and fonts throughout deck
- ✅ No typos or grammatical errors
- ✅ Numbers formatted consistently (e.g., $1,234.56 not $1234.5600)
- ✅ Color scheme is readable and professional
- ✅ Slide numbers and deck title on every slide
- ✅ Logical flow from one slide to the next

**What to Avoid:**
- ❌ Walls of text (use bullet points, not paragraphs)
- ❌ Tiny font sizes (minimum 18pt for body text)
- ❌ Low-quality screenshots or images
- ❌ Inconsistent terminology (pick "stakeholder" or "client" and stick with it)
- ❌ Overly technical jargon without explanation

---

## Part 6: Interview Preparation

### Interview Format

**Midterm Interview (covers Milestone 1):**
- **When**: Week of October 13-14, 2025
- **Duration**: 20 minutes + 5 minutes debrief
- **Format**: Individual, one-on-one with professor
- **Opening**: "Tell me about your project"
- **Coverage**: Data quality, descriptive analytics, diagnostic analytics

**Final Interview (covers Milestones 2-3):**
- **When**: Finals week, December 2025
- **Duration**: 20 minutes + 5 minutes debrief
- **Format**: Individual, one-on-one with professor
- **Opening**: "Tell me about your project"
- **Coverage**: Predictive analytics, prescriptive analytics, synthesis across all types

**What to Bring:**
- You do NOT need to walk through slides
- You should have your slides submitted beforehand (professor will review)
- Be prepared to pull up Excel/Looker if asked to show specific analysis

---

### Interview Assessment Criteria

The interview assesses different dimensions than the milestone submissions:

**Milestone Submission** = Deliverables, documentation, technical accuracy
**Interview** = Understanding, synthesis, communication under pressure

**What Professors Evaluate:**
1. **Depth of Understanding** (40%)
   - Can you explain WHY you made analytical choices?
   - Do you understand what your numbers mean?
   - Can you defend your methodology?

2. **Business Acumen** (30%)
   - Do you connect analysis to business problems?
   - Are your recommendations realistic and actionable?
   - Do you understand your stakeholder's perspective?

3. **Communication Skills** (20%)
   - Can you explain technical concepts clearly?
   - Do you structure responses logically?
   - Can you adapt to follow-up questions?

4. **Synthesis & Progression** (10%)
   - Do you see connections across analytics types?
   - Can you articulate the analytics maturity journey?
   - Do insights build on each other?

---

### Common Interview Questions

**Project Foundation:**
- "Tell me about your project." (2-3 minute opening)
- "Why did you choose this job/company/stakeholder?"
- "How does your problem connect to [Decision Area]?"

**Data Quality:**
- "What data quality issues did you find?"
- "Walk me through how you applied the Data Quality Framework for [specific issue]."
- "Why did you choose to [fix/not fix] [specific issue]?"

**Descriptive Analytics:**
- "What were the key trends you discovered?"
- "What surprised you in the data?"
- "How did you decide which metrics to focus on?"

**Diagnostic Analytics:**
- "What was the root cause of [problem]?"
- "How did you use pivot tables/slicers to drill down?"
- "Were there any root causes you expected to find but didn't?"

**Predictive Analytics:**
- "Why did [forecasting method] work better than [other method]?"
- "Explain what the regression coefficients tell you."
- "What does an adjusted R² of [X] mean?"
- "How confident are you in your forecast? What could go wrong?"

**Prescriptive Analytics:**
- "Walk me through your optimization model."
- "What are the key constraints and why do they matter?"
- "What does the sensitivity analysis tell you?"
- "Explain the probability distribution from your simulation."
- "What level of risk is acceptable and why?"

**Synthesis:**
- "How did your descriptive findings inform your predictive model?"
- "Looking across all four analytics types, what's the story?"
- "If your stakeholder could only implement ONE recommendation, which would you prioritize?"

**Challenge Questions:**
- "What would you do differently if you started over?"
- "What are the limitations of your analysis?"
- "How would you validate your recommendations?"

---

### How to Prepare for Interviews

**1. Practice Your Opening (2-3 minutes)**
Structure: Job/Company → Stakeholder → Problem → Decision Area → Brief preview of findings

Example:
> "I analyzed order fulfillment operations for a Supply Chain Analyst role at ShopNow, an e-commerce company. My stakeholder is the Fulfillment Operations Manager who is facing increasing delivery times—currently 5.2 days versus a 3-day target. This connects to the Supply Chain Management decision area because it involves optimizing how products reach customers. Through my analysis, I discovered that the root cause is warehouse location inefficiencies, predicted delivery times will continue increasing without intervention, and developed an optimization model to reduce costs by 20% while meeting delivery targets."

**2. Review Your Own Work Thoroughly**
- Re-read your slides and analysis 2-3 days before interview
- Make sure you can explain every chart, every formula, every insight
- Practice explaining technical concepts in simple terms
- Review the DC ACT Framework and be ready to map your work to it

**3. Anticipate Follow-Up Questions**
For every insight you present, ask yourself:
- "How do I know this is true?" (evidence)
- "Why does this matter?" (business impact)
- "What should we do about it?" (action)

**4. Practice Verbally**
- Record yourself answering "Tell me about your project"
- Practice with a friend or family member
- Time yourself—can you explain your key findings in 2-3 minutes?

**5. Prepare Examples**
Have specific examples ready:
- "For example, I found that Warehouse B had 40% longer delivery times..."
- "To illustrate, when I increased the budget constraint by 10%, profit increased by..."

**6. Be Honest About Limitations**
If asked something you don't know:
> "That's a great question. I didn't analyze [that specific aspect], but if I were to explore it, I would..."

---

### STAR Method for Behavioral Responses

When answering "how" or "why" questions, use STAR structure:

**S**ituation: "The problem was..."
**T**ask: "I needed to..."
**A**ction: "I approached this by..."
**R**esult: "This revealed that..."

Example:
> **S**: "The delivery time data showed increasing trends, but I didn't know why."
> **T**: "I needed to identify which factors were driving the delays."
> **A**: "I used pivot tables with slicers to break down delivery times by warehouse location, carrier, product category, and day of week."
> **R**: "This revealed that Warehouse B had consistently longer delivery times across all categories, pointing to a location-specific issue rather than a carrier or product problem."

---

## Part 7: Common Pitfalls & How to Avoid Them

### Pitfall #1: "I Can't Find Relevant Data"

**Why This Happens:**
- Problem statement is too specific or too vague
- Looking for perfect data instead of workable data
- Not using the Custom GPT effectively

**How to Avoid:**
- Start with Custom GPT—it's designed to generate exactly what you need
- Broaden your problem slightly if needed (inventory → supply chain)
- Focus on data that supports your decision area, not perfect match
- Schedule office hours EARLY if you're stuck

---

### Pitfall #2: "My Project Is Too Complicated"

**Why This Happens:**
- Trying to analyze everything instead of one focused problem
- Adding features you think will impress rather than meet requirements
- Confusing complexity with quality

**How to Avoid:**
- Start simple and build incrementally
- Focus on ONE problem statement, not multiple problems
- Meet minimum requirements first, THEN add sophistication
- Remember: Clear and correct > complicated and confusing

**Complexity Checkpoints:**
- Descriptive/Diagnostic: 1 problem, 5-8 metrics, 2-3 dimensions
- Predictive: 1 target variable, 3-8 independent variables
- Prescriptive: 3-6 decision variables, 4-6 constraints

---

### Pitfall #3: "I Don't Clearly Know My Stakeholder/Problem"

**Why This Happens:**
- Rushing into data collection before foundation is set
- Choosing a generic problem instead of specific scenario
- Not connecting to job description

**How to Avoid:**
- Complete Project Kickoff Checklist (Part 1.5) by Week 4
- Test your problem statement: Can someone else understand what the stakeholder needs?
- Use LinkedIn research to make stakeholder feel real
- Get feedback on your problem statement in office hours

---

### Pitfall #4: "My Analysis Is Technically Correct but Lacks Business Insight"

**Why This Happens:**
- Focusing only on technical execution without interpretation
- Not asking "so what?" after every finding
- Treating this as a math exercise instead of business problem-solving

**How to Avoid:**
- After every analysis step, write: "This means that..."
- Connect every insight to your stakeholder's problem
- Ask yourself: "If I were the stakeholder, what would I do with this information?"
- Use takeaway slide titles—forces you to articulate insights

---

### Pitfall #5: "My Slides Are Full of Analysis but Don't Tell a Story"

**Why This Happens:**
- Dumping every analysis into slides
- Organizing by technique instead of by insight
- Not using takeaway titles

**How to Avoid:**
- Start with takeaway titles BEFORE creating slides
- Select only the most important 3-5 insights per analytics type
- Each slide should answer: "What did I learn and why does it matter?"
- Less is more—cut anything that doesn't support your recommendations

---

### Pitfall #6: "I'm Panicking the Night Before Deadline"

**Why This Happens:**
- Underestimating time required for analysis and slides
- Procrastinating because project feels overwhelming
- Technical issues with tools (Excel, Looker, Solver)

**How to Avoid:**
- Start each milestone 2 weeks before deadline
- Break work into small daily tasks
- Get data cleaned and analyzed 1 week before deadline (gives you time for slides)
- Test Excel Solver and Looker EARLY, not night before
- Schedule office hours if you get stuck—don't wait until deadline

**Recommended Timeline per Milestone:**
- 2 weeks before: Data collection and cleaning
- 10 days before: Technical analysis (Excel, Looker)
- 5 days before: Slides and interpretation
- 2 days before: Review, polish, practice explaining
- Deadline day: Final submission checklist

---

## Part 8: Resources & Support

### Custom GPT: Data Craft
- **Access**: [Link will be provided in Brightspace]
- **User Guide**: See "How to Use Data Craft GPT" document in Brightspace
- **What It Does**: Generates customized operational datasets tailored to your job, problem, and decision area
- **When to Use**: Before you start data collection (Week 3-4)

---

### Office Hours
- **When**: [Schedule will be posted in Brightspace]
- **What to Bring**: Your project foundation (job, stakeholder, problem), specific questions, partially completed work
- **Best Times to Come**:
  - Week 3-4: Review project foundation before data collection
  - 1 week before each milestone: Review analysis and get feedback on insights
  - Anytime you're stuck: Don't wait until deadline

---

### Example Projects
**See Brightspace for:**
- Example project showing all four analytics types
- Sample slides with excellent takeaway titles
- Sample data quality assessment
- Sample Excel workbooks with clear formatting

---

### Technical Support
- **Excel Help**: Data Analysis Toolpak tutorials in Brightspace
- **Looker Studio**: Dashboard building tutorials in Brightspace
- **Solver Add-In**: Optimization model tutorials in Brightspace
- **Monte Carlo**: Simulation tutorials in Brightspace

---

### Peer Support
- **Study Groups**: Consider forming study groups to discuss projects (individual work, but shared learning)
- **Peer Review**: Exchange slides with classmates for feedback on clarity (before submission)

---

## Part 9: Frequently Asked Questions (FAQ)

### General

**Q: Can I work with a partner or group?**
A: No. This project must be completed individually. The goal is for you to own this work completely so you can discuss it confidently in job interviews.

**Q: Can I use the same dataset for all three milestones?**
A: You MUST use the same dataset for Descriptive + Diagnostic. You MAY use different datasets for Predictive and Prescriptive if your original dataset doesn't support those analyses. However, simpler is often better—try to use the same dataset throughout if possible.

**Q: What if I find a great job posting but it gets removed before the deadline?**
A: This is why you save it as a PDF immediately. The saved PDF is what you'll submit.

**Q: My job description doesn't explicitly mention data or analytics. Is that okay?**
A: Yes! Almost every operations role involves data-driven decision-making even if not explicitly stated. Focus on the operational challenges the role addresses and how data could help solve them.

---

### Data Collection

**Q: What if the Custom GPT doesn't generate exactly what I need?**
A: The GPT asks you questions to customize data. If it's not quite right, you can iterate by providing more specific requirements. You can also bring your own data if you find a better source.

**Q: Can I use data from my internship or job?**
A: Yes, IF you have explicit permission and anonymize any sensitive information. Save the permission email and include it with your submission.

**Q: How do I know if my dataset is "good enough"?**
A: Minimum requirements: 500 rows, 5+ variables, relevant to your problem, includes data quality issues to fix. If you meet these, you're good. Quality > quantity.

**Q: What if my data doesn't have quality issues?**
A: Real data always has quality issues. Look harder. If it's truly perfect (unlikely), you must artificially introduce issues for the learning exercise. Data quality assessment is a required competency.

---

### Technical Analysis

**Q: I've never used Looker Studio. How do I start?**
A: See the Looker Studio tutorial in Brightspace. Start with connecting your data source, then add charts one at a time. Office hours can help troubleshoot.

**Q: Excel Solver isn't finding a solution. What do I do?**
A: Common issues: (1) Constraints are impossible (too restrictive), (2) Formulas have errors, (3) Solver settings need adjustment. See Solver troubleshooting guide in Brightspace or visit office hours.

**Q: My R² is only 0.45. Is that bad?**
A: Not necessarily! R² depends on your data and problem. Discuss what this means for your business application. "Low" R² might still provide valuable insights. What matters is interpretation, not hitting a specific number.

**Q: How many simulation runs should I do?**
A: Minimum 1,000. Recommended 5,000-10,000. More runs = more stable results. Stop when adding runs doesn't change your conclusions.

---

### Slides & Communication

**Q: Can I have more than 5 slides per analytics type?**
A: Yes, but be strategic. More slides doesn't always mean better communication. If you have genuinely important insights that need 6-7 slides, that's fine. But avoid padding.

**Q: Do I need to include my Excel workbook screenshots in slides?**
A: Include visuals that support your insights. This could be charts from Excel, dashboard screenshots from Looker, or tables showing key results. Don't just paste raw Excel screenshots—extract the insight.

**Q: What if I can't think of a good takeaway title?**
A: Start with your data → insight → takeaway formula:
1. What does the data show? "Delivery times increased by 40%"
2. What caused it? "Western region warehouse"
3. Combine: "Delivery Times Increased 40% Due to Western Region Warehouse Issues"

**Q: Should I include an appendix with detailed calculations?**
A: You can, but it's not required. Your Excel workbook is your detailed documentation. Slides should communicate insights, not show every calculation.

---

### Interviews

**Q: Will you ask me to explain specific formulas or calculations?**
A: Possibly. You should understand how your analysis works, not just what the output says. Example: "Explain how exponential smoothing works" or "What does this coefficient mean?"

**Q: What if I get a question I can't answer?**
A: Be honest. Say "I don't know, but here's how I would figure it out..." or "I didn't analyze that aspect, but if I did..." Intellectual honesty is valued.

**Q: Can I reference my slides or Excel during the interview?**
A: Yes! You're not expected to memorize every number. Pull up your materials if needed to answer questions accurately.

**Q: How much should I talk vs. wait for questions?**
A: Open with 2-3 minute overview, then the interview becomes conversational. I'll ask questions, you answer, I'll probe deeper. It's a dialogue, not a presentation.

---

### Grading & Deadlines

**Q: What if I miss a milestone deadline?**
A: Standard late policy applies [reference your syllabus]. Projects not submitted by deadline may receive reduced credit or zero. Plan ahead and communicate if you have extenuating circumstances.

**Q: If I do poorly on Milestone 1, can I still get an A on the project?**
A: Yes. Each milestone is independently graded. Learn from feedback and improve in subsequent milestones.

**Q: How much weight is the interview vs. the submission?**
A: Interview is separate from project milestones. Milestone submissions = 45 points total (15 each). Interviews = 40 points total (Midterm 15, Final 25). Both matter significantly.

**Q: Will you provide feedback between milestones?**
A: Yes. Feedback on Milestone 1 will be provided before Milestone 2 is due. Use this feedback to improve.

---

## Part 10: Success Criteria & Stretch Goals

### What Does "Excellent" Look Like?

**Beyond Meeting Requirements:**
Meeting minimum requirements earns a B grade. Excellence requires going deeper:

#### Data Quality (Excellent)
- Identify 4-5+ quality issues across multiple dimensions
- Thorough assessment of business ramifications
- Root cause analysis shows deep thinking (not just "data entry error")
- Strategic decisions on what to fix vs. what to document

#### Technical Analysis (Excellent)
- Analysis reveals non-obvious patterns
- Multiple analytical approaches compared
- Sensitivity analysis shows "what if" thinking
- Professional documentation and formatting throughout

#### Business Insights (Excellent)
- Insights connect explicitly to Operations Management Decision Area
- Recommendations are specific with implementation roadmap
- Risk and limitation discussion shows maturity
- Connects individual insights into coherent story

#### Communication (Excellent)
- Every slide has compelling takeaway title
- Visuals are optimized for insight (not just default charts)
- Storytelling flows logically from problem → analysis → recommendation
- Professional polish (design, formatting, no errors)

---

### Stretch Goals for Ambitious Students

If you want to go beyond requirements and build a truly impressive portfolio piece:

#### Descriptive/Diagnostic
- [ ] Create interactive Looker dashboards with multiple drill-down paths
- [ ] Include comparative analysis (this year vs. last year, this region vs. industry benchmark)
- [ ] Statistical hypothesis testing to validate root causes

#### Predictive
- [ ] Compare 4+ forecasting methods, not just the required 2
- [ ] Test multiple regression models and explain which performs best
- [ ] Include confidence intervals on forecasts
- [ ] Forecast accuracy validation using hold-out data

#### Prescriptive
- [ ] Multi-objective optimization (optimize for profit AND service level)
- [ ] Scenario planning with 3+ "what if" analyses
- [ ] Advanced simulation with multiple uncertain variables
- [ ] Combine optimization + simulation (optimize under uncertainty)

#### Communication
- [ ] Executive summary slide (1-page synthesis of entire project)
- [ ] Implementation timeline with milestones and owners
- [ ] Financial impact analysis (ROI of recommendations)
- [ ] Change management considerations for implementation

---

### Portfolio-Ready Checklist

Your project is portfolio-ready when:
- [ ] You can explain the entire project in 3 minutes to someone unfamiliar with the course
- [ ] Every slide has a compelling takeaway title
- [ ] Recommendations are specific enough to implement
- [ ] You've connected your analysis to the 10 Operations Management Decision Areas
- [ ] You can defend every analytical choice you made
- [ ] Your slides look professional enough to show in a real job interview
- [ ] You've practiced explaining this project out loud
- [ ] You can articulate the business impact (not just the technical results)

---

## Conclusion

This project is your opportunity to demonstrate **end-to-end analytics capability**—from defining a business problem, to collecting and cleaning data, to applying sophisticated analytical techniques, to communicating actionable insights.

**Key Takeaways:**
1. **Foundation First**: Spend time in Weeks 3-4 getting your job, stakeholder, and problem right
2. **Use Frameworks**: DC ACT, Data Quality Framework, and 10 Decision Areas guide your work
3. **Focus on Insights**: Technical correctness is necessary but not sufficient—interpret what it means
4. **Communicate Clearly**: Takeaway titles, supporting visuals, professional polish
5. **Prepare for Interviews**: Practice explaining your work—you'll need this skill in job interviews

**This project is worth 45% of your grade, but more importantly, it's a career asset you'll reference for years.**

Good luck! Use office hours. Start early. Make it something you're proud to show future employers.

---

## Appendix: Quick Reference

### Project Timeline Overview
- **Week 3-4**: Complete Project Foundation (job, stakeholder, problem, decision area)
- **Week 5-7**: Milestone 1 work (Descriptive + Diagnostic)
- **Week 7** (Oct 13): Milestone 1 Due + Midterm Interviews
- **Week 8-10**: Milestone 2 work (Predictive)
- **Week 10** (Nov 4): Milestone 2 Due
- **Week 11-14**: Milestone 3 work (Prescriptive)
- **Week 14** (Dec 4): Milestone 3 Due
- **Finals Week**: Final Interviews

### Submission Checklist Template

**Milestone 1:**
- [ ] Slides (3-5 slides)
- [ ] Data Quality Assessment Report
- [ ] Original Data File
- [ ] Cleaned Data File
- [ ] Excel Analysis Workbook
- [ ] Looker Dashboard Links Document
- [ ] Job Posting PDF

**Milestone 2:**
- [ ] Slides (cumulative, 6-10 slides)
- [ ] Excel Analysis Workbook (forecasting + regression)
- [ ] Data File (if new)
- [ ] Data Quality Assessment (if new dataset)

**Milestone 3:**
- [ ] Slides (cumulative, 9-15 slides)
- [ ] Excel Analysis Workbook (optimization + simulation)
- [ ] Data File (if new)
- [ ] Data Quality Assessment (if new dataset)

### File Naming Convention
`[LastName]_[FirstName]_Milestone[X]_[Component].[ext]`

Examples:
- `Smith_John_Milestone1_Slides.pptx`
- `Smith_John_Milestone2_Analysis.xlsx`
- `Smith_John_Milestone3_Data.csv`

---

**Document Version**: 1.0
**Last Updated**: September 30, 2025
**Questions?** Email or visit office hours [schedule in Brightspace]
