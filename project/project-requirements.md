# BCOR 3750 Project Requirements

## Table of Contents

- [Progressive Analytics Across the Maturity Scale](#progressive-analytics-across-the-maturity-scale)
- [Part 1: Project Foundation](#part-1-project-foundation)
- [Part 2: Data Collection & Quality (All Milestones)](#part-2-data-collection--quality-all-milestones)
- [Part 3: Milestone Requirements](#part-3-milestone-requirements)
- [Part 4: Grading Rubrics](#part-4-grading-rubrics)
- [Part 5: Presentation & Communication Guidelines](#part-5-presentation--communication-guidelines)
- [Part 6: Interview Preparation](#part-6-interview-preparation)
- [Part 7: Common Pitfalls & How to Avoid Them](#part-7-common-pitfalls--how-to-avoid-them)
- [Part 8: Frequently Asked Questions (FAQ)](#part-8-frequently-asked-questions-faq)
- [Conclusion](#conclusion)
- [Appendix: Quick Reference](#appendix-quick-reference)

---

## Progressive Analytics Across the Maturity Scale

### Project Overview

This semester-long project is your opportunity to build a **portfolio-quality analytics case study** that demonstrates your ability to solve real operational problems using data. You will progress through all four analytics types, **Descriptive, Diagnostic, Predictive, and Prescriptive**, while building skills that directly transfer to professional roles related to operations and supply chain management.

**Why This Matters for Your Career:**

- **Portfolio Piece**: Showcase this project in job interviews to demonstrate analytics capabilities
- **Real-World Skills**: Apply the exact tools and techniques used by operations analysts daily (decision making with data, Excel, dashboards, forecasting, optimization)
- **Transferable Experience**: Based on a real job description you want to pursue

### Project Weight

- **Total**: 45% of your final grade (15% per milestone)
- **Milestone 1** (Descriptive + Diagnostic): 15% of final grade - Due **Monday, October 20, 2025**
- **Milestone 2** (Predictive): 15% of final grade - Due **Tuesday, November 11, 2025**
- **Milestone 3** (Prescriptive): 15% of final grade - Due **Thursday, December 4, 2025**

**Note**: Each milestone is graded out of **100 points**, then converted to 15% of your final course grade.

---

### How to Use Your Excel Workbook and Slide Deck

For each milestone, you will submit **two separate files** that serve distinct purposes:

#### **Excel Workbook = Technical Analysis Workspace**
- **Purpose**: This is your "behind-the-scenes" work where all calculations, tables, charts, pivot tables, and dashboards live
- **Content**: Raw data, cleaned data, formulas, statistical calculations, pivot tables, charts, dashboards
- **What NOT to include**: NO interpretation text, NO text boxes explaining insights, NO business implications written in cells
- **Think of it as**: Your technical laboratory where you perform all the analysis

#### **Slide Deck = Business Communication & Insights**
- **Purpose**: This is THE ONLY place where you interpret your findings and communicate insights to stakeholders
- **Content**: Screenshots of specific visuals from Excel + your written interpretations following the Insight → Recommendation → Prediction format
- **What to include**: Takeaway titles, selected visuals, business interpretations, recommendations, predictions
- **Think of it as**: Your executive presentation that tells the business story

#### **Why This Separation?**
1. **Clarity**: Keeps technical work separate from business communication
2. **Grading**: Easier to evaluate - one clean slide deck with all insights vs. hunting through Excel workbook
3. **Professional Practice**: Mirrors real-world analytics work where you analyze in Excel/tools but present insights in slides/reports
4. **Focus**: Excel shows "what you did," slides explain "what it means and what to do about it"

#### **The Workflow**
1. **Analyze in Excel**: Calculate statistics, build pivot tables, create charts and dashboards
2. **Screenshot specific visuals**: Take ONE focused chart/table per slide that tells the key story
3. **Interpret in slides**: Add the visual to a slide with takeaway title and Insight/Recommendation/Prediction bullets

**Remember**: Excel = calculations and visuals only | Slides = ALL interpretations and insights

### Core Frameworks

Throughout this project, you will apply:

**5-Step Analytics Framework**

1. **Define** the business problem
2. **Collect** and prepare the data
3. **Analyze** the data and generate insights
4. **Communicate** the insights, recommendations, and predictions
5. **Act** and track the change

**Data Quality Framework**

1. **Identify** the data quality issue
2. **Assess** the business ramification
3. **Analyze** the root cause
4. **Decide** on the best option (Remove / Update / Do Nothing)
5. **Fix** the issue, if applicable

**10 Operations Management Decision Areas**

1. Design of Goods & Services
2. Quality Management
3. Process & Capacity Design
4. Location Strategy
5. Layout Strategy
6. Human Resources & Job Design
7. Supply Chain Management
8. Inventory Management
9. Scheduling
10. Maintenance

---

## Part 1: Project Foundation

### 1.1 Job Description Selection

Find and save a **real, currently posted job** in operations or supply chain management that you can realistically see yourself pursuing.

**Specifications:**

- **Career Level**: Entry-level positions (analyst, coordinator, specialist roles)
- **Industry**: Any industry, but job must be related to operations/supply chain management in some way
- **Company**: Must be a real, operating company
- **Justification**: Be prepared to explain how this role connects to ops/SCM

**Action Items:**

1. Search job boards (LinkedIn, Indeed, company career sites) for relevant positions
2. Select ONE job that interests you and aligns with your career goals
3. **Save the complete job posting as a PDF** (in case it disappears later) and name the file `job-posting-fname-lname.pdf`
4. Review the job description to identify:

   - Key responsibilities related to data and analytics
   - Metrics or KPIs mentioned
   - Operational challenges the role addresses
   - Tools or systems mentioned

5. **Optional**: Use the chatbot at https://r.isba.co/chat to connect your resume to the job description and generate a high-level project spec. The chatbot is useful for understanding the job description and how it connects to your experience.

---

### 1.2 Operations Management Decision Area Selection

**Requirement**: Select ONE primary Operations Management Decision Area that aligns with your job description and will be the focus of your entire project.

**The 10 Decision Areas:**

1. **Design of Goods & Services**: What product or service are we creating, and who is it for?
2. **Quality Management**: How do we meet expectations every time?
3. **Process & Capacity Design**: How will the work get done, and how much can we produce?
4. **Location Strategy**: Where should we set up to serve customers best?
5. **Layout Strategy**: How do we arrange people, machines, or space for smooth flow?
6. **Human Resources & Job Design**: Who does the work, and how do we design jobs people want to do?
7. **Supply Chain Management**: Where do our materials come from, and how do products reach customers?
8. **Inventory Management**: How much should we keep in stock, and when should we restock?
9. **Scheduling**: When should people, machines, and tasks be assigned?
10. **Maintenance**: How do we keep everything running reliably over time?

**Action Items:**

1. Review your job description and identify which decision area(s) it addresses
2. Select ONE primary decision area as your project focus
3. Write 2-3 sentences justifying your selection based on the job responsibilities

**Example:**

> "I selected **Supply Chain Management** as my decision area because the Supply Chain Analyst role at Amazon focuses on optimizing order fulfillment and delivery performance. The job description mentions analyzing delivery times, carrier performance, and distribution network efficiency—all core supply chain decisions."

---

### 1.3 Stakeholder Identification

**Requirement**: Identify a **specific stakeholder** who would benefit from your analysis. This should be a real person (when possible) with the job title and responsibilities described in your target role.

**Specifications:**

- **Job Title**: Specific title from job posting or related role (e.g., "Warehouse Operations Manager" not just "Manager")
- **Department**: Which department does this person work in?
- **Responsibilities**: What are their main operational responsibilities?
- **LinkedIn Research**: Find a real person on LinkedIn with this role at your target company (or similar company) and include their LinkedIn profile URL

**Why LinkedIn Research?**

- Makes your project feel like a real consulting engagement
- Helps you understand what the role actually does
- Prepares you for networking and informational interviews
- Adds authenticity when discussing this project in job interviews

**Action Items:**

1. Identify the stakeholder title from your job description
2. Research this role on LinkedIn at your target company
3. Document:
   - Stakeholder name (if found)
   - Job title
   - Company
   - LinkedIn profile URL
   - 2-3 key responsibilities related to your analysis
4. Add these details to **Slide 1: Project Overview** in your slide deck (see Section 4: Communicate for slide instructions) so the stakeholder information is included in your milestone submission

---

### 1.4 Problem Statement Development

**Requirement**: Define a clear, specific business problem that your stakeholder needs to solve using data. This problem will guide ALL your analytics work.

**Problem Statement Template:**

> "[Stakeholder] at [Company] is facing [problem] which is causing [impact]."

**Examples by Decision Area:**

**Supply Chain Management:**

> "The Fulfillment Operations Manager at ShopNow is facing increasing delivery times which is causing customer complaints to rise."

**Inventory Management:**

> "The Inventory Analyst at TechParts Inc. is facing high carrying costs (the Carrying Cost metric is well above the industry benchmark) combined with frequent stockouts (the SKU Stockout Rate shows a significant portion of items out of stock each week)."

**Process & Capacity Design:**

> "The Production Planning Manager at AutoSupply Manufacturing is facing unpredictable production output which is causing missed customer order deadlines."

**Quality Management:**

> "The Quality Manager at FoodCo is facing increasing defect rates which is causing customer returns and warranty costs to increase."

**Action Items:**

1. Draft your problem statement using the template
2. Ensure it includes:
   - Specific stakeholder and company
   - Measurable challenge (with numbers if possible)
   - Business impact (why this matters)
   - Current state (what's not working)
   - Desired outcome (what success looks like)
3. Validate that this problem can be analyzed with data

---

### 1.5 Project Kickoff Checklist

- [ ] Job posting saved as PDF
- [ ] Job title and company documented
- [ ] Operations Management Decision Area selected and justified
- [ ] Stakeholder identified (name, title, LinkedIn URL if possible)
- [ ] Problem statement drafted (includes challenge, impact, current state, desired outcome)
- [ ] Problem connects clearly to Decision Area
- [ ] Problem can be analyzed using data

---

## Part 2: Data Collection & Quality (All Milestones)

### 2.1 Data Sources

You have **two options** for data collection:

#### Option 1: Custom GPT Data Generator (Recommended)

Use the **Data Craft Custom GPT** to generate realistic synthetic operational data tailored to your specific problem.

**Advantages:**

- Generates data specifically designed for your job/problem/decision area
- Includes intentional data quality issues for learning
- Creates data structured for all four analytics types
- Provides data dictionary and analysis guidance

**How to Use:**

1. Access Data Craft Custom GPT: https://chatgpt.com/g/g-jJHuZrEPM-data-craft
2. Upload your job description PDF
3. Answer questions ONE AT A TIME as the GPT guides you
4. The GPT will generate customized datasets with documentation

#### Option 2: Bring Your Own Data

Collect data from public sources, Kaggle, company internships (with permission), or other legitimate sources.

**Requirements if using your own data:**

- **Minimum size**: 500 rows, 5+ variables
- **Data quality**: Must include realistic data quality issues (if your data is perfect, you must artificially introduce issues for the learning exercise)
- **Relevance**: Data must directly relate to your job description, decision area, and problem statement
- **Documentation**: Create your own data dictionary explaining all fields

**Acceptable Public Data Sources:**

**🏛️ Government & Public Sector Data:**

- [Data.gov](https://data.gov) - U.S. federal government open data portal (transportation, commerce, agriculture, health)
- [California Open Data](https://data.ca.gov) - State-level datasets including business, employment, and infrastructure
- [Los Angeles Open Data](https://data.lacity.org) - City-level data on services, operations, and performance metrics
- [Census.gov](https://data.census.gov) - Economic, demographic, and business data (County Business Patterns, Economic Census)

**📊 Business & Financial Data:**

- [Kaggle Datasets](https://www.kaggle.com/datasets) - Curated datasets across industries (supply chain, retail, manufacturing, logistics)
- [Data.World](https://data.world) - Collaborative data platform with business operations datasets
- [Quandl](https://quandl.com) - Financial and economic time series data (useful for forecasting)
- [FiveThirtyEight Data](https://data.fivethirtyeight.com) - Well-documented datasets with clear data dictionaries

**🏫 Academic & Research Sources:**

- [LMU Library Business Databases](https://libguides.lmu.edu/c.php?g=323523&p=2167835) - Access through library portal (IBISWorld, Statista, market research)
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) - Classic datasets for regression and prediction
- [Harvard Dataverse](https://dataverse.harvard.edu) - Research datasets from academic studies

**🔍 Data Discovery Tools:**

- [Google Dataset Search](https://toolbox.google.com/datasetsearch) - Search engine for datasets across repositories
- [Data Is Plural Newsletter](https://www.data-is-plural.com) - Weekly curated list of interesting datasets
- [r/datasets (Reddit)](https://www.reddit.com/r/datasets/) - Community-curated dataset recommendations

**💼 Industry-Specific Sources:**

- **Supply Chain/Logistics**: Bureau of Transportation Statistics, Port Authority data, FRED Economic Data
- **Retail/E-commerce**: Public company datasets, retail sales data from Census Bureau
- **Manufacturing**: NIST Manufacturing Data, industry production indices
- **Healthcare Operations**: CMS.gov, Hospital Compare datasets, CDC data

**📋 Dataset Selection Criteria:**

- ✅ Minimum 500 rows, 5+ variables
- ✅ Includes time-stamped or categorical dimensions for analysis
- ✅ Relevant to operations/supply chain management context
- ✅ Has data dictionary or clear field descriptions
- ✅ Realistic data quality issues present (or can be introduced)

---

### 2.2 Excel Workbook Setup

**Create your main Excel workbook** using this exact naming convention:

- **Filename**: `milestone-01-fname-lname.xlsx`
  - Example: `milestone-01-john-smith.xlsx`
  - Use your actual first and last name (no brackets)
  - All lowercase (milestone, fname, lname)
  - Replace "fname" with your first name and "lname" with your last name

This workbook will contain all your technical analysis for Milestone 1. You will add additional worksheets and analyses in Milestones 2 and 3.

---

### 2.3 Data Relevance

Your data must be relevant to your project through AT LEAST ONE of these connections:

1. **Job Function**: Data directly relates to the responsibilities in your job description

   - Example: Job is "Logistics Analyst" → Data is shipment/delivery data
2. **Company**: Data comes from or represents your target company's industry

   - Example: Job is at Amazon → Data is e-commerce order fulfillment data
3. **Industry**: Data represents typical operations in your target industry

   - Example: Job is in healthcare supply chain → Data is hospital inventory/patient flow data

**You may use different datasets for different analytics types:**

- **Descriptive + Diagnostic**: MUST use the same dataset (you're analyzing what happened and why)
- **Predictive**: Can use the same dataset as Descriptive/Diagnostic OR a different dataset if needed
- **Prescriptive**: Can use the same dataset OR a different dataset if the original doesn't support optimization/simulation

**Why allow different datasets?**
Sometimes your descriptive/diagnostic dataset doesn't have the right structure for time series forecasting, regression, or optimization. It's better to use appropriate data than to force the wrong data into an analysis technique.

---

### 2.4 Data Quality Assessment (Required for Milestone 1)

**Step 1: Create Data Dictionary**

Before assessing data quality, you must first document your dataset structure by creating a **Data_Dictionary** worksheet in your Excel workbook.

**Data Dictionary Requirements:**

Create a worksheet called **Data_Dictionary** with the following columns:


| Column Name | Data Type | Notes                                        |
| ------------- | ----------- | ---------------------------------------------- |
| Customer_ID | Text      | Unique identifier for each customer          |
| Order_Date  | Date      | Date order was placed (MM/DD/YYYY format)    |
| Order_Qty   | Number    | Quantity of items ordered                    |
| Region      | Text      | Geographic region (North, South, East, West) |

**Required Columns:**

1. **Column Name**: The exact field name from your dataset
2. **Data Type**: Text, Number, Date, Boolean, etc.
3. **Notes**: Any additional context such as:
   - Valid value ranges (e.g., "Values between 0-100")
   - Format specifications (e.g., "MM/DD/YYYY")
   - Business rules (e.g., "Cannot be negative")
   - Categories or codes (e.g., "N, S, E, W for regions")
   - Special handling notes

**Format Requirements:**

- Create this as a new worksheet tab called **Data_Dictionary**
- Include ALL columns from your dataset
- Use table formatting for readability
- Place this worksheet before your Data_Cleaning_Log in the workbook

---

**Step 2: Identify and Fix Data Quality Issues**

**Requirement**: Use the **Data Quality Framework** to identify, assess, and fix data quality issues.

**Data Quality Framework:**

1. **Identify** the data quality issue (what type of issue is it?)
2. **Assess** the business ramification (why does this matter?)
3. **Analyze** the root cause (why did this issue occur?) - provide a hypothetical reason
4. **Decide** on the best option (Remove / Update / Do Nothing)
5. **Fix** the issue, if applicable (implement your decision)

**Data Quality Dimensions**:

- **Availability**: Is the data accessible when needed?
- **Accuracy**: Is the data correct and free from errors?
- **Completeness**: Are all required data points present?
- **Consistency**: Is the data uniform across sources/fields?
- **Validity**: Does the data conform to business rules?
- **Uniqueness**: Are there duplicate records?
- **Timeliness**: Is the data current and up-to-date?

**Minimum Requirements:**

- Identify and document **at least 3 different types** of data quality issues
- For EACH issue, complete all 5 framework steps
- Fix critical issues that would impact analysis accuracy
- Document issues you chose NOT to fix and explain why

**Common Data Quality Issues:**

- Missing Values
- Duplicate Records
- Date Format Inconsistencies
- Outliers
- Inconsistent Categories
- Inaccurate Values

**Deliverable**:

Create a **Data_Cleaning_Log** worksheet in your Excel workbook with these columns:


| Column                   | Description                                | Example                                                                                  |
| -------------------------- | -------------------------------------------- | ------------------------------------------------------------------------------------------ |
| **Column**               | Which field has the issue                  | "Vendor_ID", "Order_Qty", "Region"                                                       |
| **Issue**                | Type of data quality issue                 | "Inaccurate Vendor_ID", "Missing Order_Qty", "Inconsistent Region"                       |
| **Ramification**         | Business impact (why this matters)         | "Can't accurately analyze vendors", "Misguided inventory decisions"                      |
| **Root Cause**           | Hypothetical reason why the issue occurred | "Data entry rules not enforced", "Human error", "Lack of validation"                     |
| **Decision**             | Your decision                              | "Update", "Remove", "Do Nothing"                                                         |
| **File Fix Method**      | How you fixed it (if applicable)           | "Created Vendor_ID_Std column with standardized values", "Imputed with central tendency" |
| **Preventative Measure** | How to prevent in future                   | "Make Vendor_ID mandatory with validation list", "Assign data steward"                   |

**Format Requirements:**

- Create this as a new worksheet tab called **Data_Cleaning_Log** in your main Excel workbook
- Use the exact column headers shown in the table above
- One row per data quality issue (minimum 3 rows)
- Apply table formatting for readability
- Add a **Summary section** below your table with:
  - Total records in original dataset: [X]
  - Total records after cleaning: [X]
  - Records removed: [X] ([X]%)
  - Records updated: [X] ([X]%)
  - Issues identified but not fixed: [X] (with justification)

**Example Entry:**


| Column    | Issue                | Ramification                                                                                               | Root Cause                                                                                          | Decision | File Fix Method                                                                                                                                      | Preventative Measure                                                                                           |
| ----------- | ---------------------- | ------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------- | ---------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------- |
| Vendor_ID | Inaccurate Vendor_ID | - Missing audit documentation<br>- Can't accurately analyze vendors<br>- Can't allocate costs to suppliers | Data entry rules were not designed or enforced for Vendor_ID. Nobody was responsible for the rules. | Update   | Create Vendor_ID_Std column to hold standardized version of Vendor_ID. Use V999 as Vendor_ID if Vendor_ID does not exist in the Vendor lookup table. | Make Vendor_ID mandatory and must match a list of known Vendor_IDs. Assign someone to enforce data validation. |

---

### 2.4 Data Requirements by Analytics Type

#### Descriptive Analytics (Milestone 1)

**Data Structure Needed:**

- Time-stamped data (dates for trend analysis)
- Numeric metrics (for summary statistics)
- Categorical dimensions (for grouping and comparisons)
- Minimum 6 months of data recommended (for meaningful trends)

**Example Fields:**

- Date/timestamp, transaction ID, metric values (revenue, quantity, time), categories (region, product, customer segment)

---

#### Diagnostic Analytics (Milestone 1)

**Data Structure Needed:**

- Same dataset as Descriptive
- Multiple categorical dimensions for drilling down
- Sufficient granularity to identify patterns

**Example Fields:**

- All fields from Descriptive, PLUS dimensions for root cause analysis (warehouse location, shift, day of week, product category, etc.)

---

#### Predictive Analytics (Milestone 2)

**For Time Series Forecasting:**

- Sequential time-stamped data with NO GAPS (daily, weekly, or monthly)
- At least 12-24 months of historical data
- Clear trends or seasonal patterns
- Target variable to forecast (demand, delivery time, defect rate, etc.)

**Example Fields:**

- Date (sequential), target_metric (what you're forecasting), optional: external factors (marketing spend, weather, holidays)

**For Regression Analysis:**

- 500-1000 records minimum
- Dependent variable (what you're predicting)
- 3-8 independent variables (factors that influence the dependent variable)
- Mix of continuous and categorical variables

**Example Fields:**

- Record ID, dependent_variable (delivery time), independent_variables (distance, weight, carrier, weather, is_express, etc.)

---

#### Prescriptive Analytics (Milestone 3)

**For Linear Programming (Optimization):**

- Decision variables (what you're deciding: product quantities, resource allocations, etc.)
- Objective function coefficients (profit per unit, cost per unit, etc.)
- Constraint parameters (budget limits, capacity limits, minimum requirements)
- 3-10 decision variables recommended

**Example Structure:**

- Decision variables table (products with profit/cost per unit)
- Constraints table (budget, capacity, minimum/maximum limits)
- Resource usage matrix (how much of each resource each decision uses)

**For Monte Carlo Simulation:**

- Historical data showing variability (250-500 records)
- Uncertain variables (demand, lead time, defect rate, etc.)
- Probability distributions (mean, standard deviation, min, max)

**Example Structure:**

- Historical variability data (showing past values of uncertain variables)
- Distribution parameters table (mean, std dev, min, max for each uncertain variable)

---

## Part 3: Milestone Requirements

### Milestone 1: Descriptive & Diagnostic Analytics

**Due: Monday, October 20, 2025 by 8:00 AM**
**Weight: 15 points**

#### What You're Answering:

- **Descriptive**: "What happened?" - Summary, trends, patterns
- **Diagnostic**: "Why did it happen?" - Root cause analysis

#### Excel Analysis:

**Descriptive Statistics Worksheet:**
Create a dedicated worksheet called **Descriptive_Statistics** that analyzes your **primary metric of interest** (the key metric related to your problem statement) using the Descriptive Statistics tool from the Data Analysis ToolPak.

Calculate all measures of central tendency (mean, median, mode) and variability (standard deviation, range, coefficient of variation). This analysis will support **Slide 5** (Primary Metric Definition), **Slide 6** (Central Tendency Insight), and **Slide 7** (Variability Insight). See the detailed slide instructions in **section 4. Communicate** for specific requirements on how to present and interpret these statistics.

---

**Diagnostic Analytics:**
Create a dedicated worksheet called **Diagnostic_Pivot_Tables** that performs root cause analysis.

**Requirements:** Create **minimum 2 pivot tables**, each with the following components:

**Structure (for each pivot table):**

- Row labels: At least 1 categorical variable (e.g., Region, Product Category, Warehouse, Shift)
- Values: Numeric metric with aggregation (e.g., Average Delivery Time, Sum of Sales, Count of Defects)
- Note: Pivot Table #2 can use 1-2 categorical variables; one dimension can overlap with Pivot Table #1

**Required Enhancements (for each pivot table):**

- Pivot chart (choose the chart type that best tells your story)
- At least one slicer for interactive filtering (slicers can be shared across both Pivot Tables)
- Conditional formatting to highlight patterns (color scales or data bars)
- Professional formatting: descriptive labels, banded rows, sorted by performance

**Excel Worksheet Purpose**:

- This worksheet contains technical analysis only (pivot tables, charts, slicers)
- **NO interpretation text in Excel** - no text boxes or cells explaining patterns
- All insights, root cause analysis, and business implications will be documented in your slide deck

**Dashboard Requirements:**

You have two options for creating your dashboards:

**Option 1: Excel Dashboards** (within your main Excel workbook)

- Create dashboard tabs within your Excel workbook using pivot charts, slicers, and formatted visuals
- Advantage: Everything in one file, no external dependencies

**Option 2: External Dashboard Tool** (Tableau, Power BI, Looker Studio)

- Create dashboards in your preferred tool
- **MUST be publicly accessible** (anyone with link can view - no login required)
- Include dashboard URLs in a **Dashboard_Links** tab in your Excel workbook
- Provide brief description of each dashboard with the URL

**Dashboard #1: Strategic Dashboard (For Executives)**

- **Purpose**: High-level view of what happened - answers "What are the key business outcomes?"
- **Audience**: Executives who need quick insights without deep operational details
- **Required Components** (MUST include all):
  - **At least 2 scorecards** at the top of the dashboard showing key KPIs with comparisons (e.g., current vs. previous period, actual vs. target)
  - **1 line chart** showing trend over time
  - **1 bar chart** showing high-level comparison across categories
  - **At least 1 slicer or filter** to make the dashboard interactive (e.g., date range selector, region filter, product category filter)
  - **Cross-filtering enabled** (if possible in your tool): clicking on one visual filters other visuals
  - Focus on summary metrics and overall performance
  - Additional charts/visuals are welcome

**Dashboard #2: Operational Dashboard (For Operations Staff)**

- **Purpose**: Detailed view for root cause analysis - answers "Why is this happening and where?"
- **Audience**: Operations managers/analysts who need granular details to make tactical decisions
- **Required Components** (MUST include all):
  - **At least 2 scorecards** at the top of the dashboard showing key operational KPIs with comparisons
  - **1 line chart** drilling into time-based patterns (e.g., daily/weekly trends, seasonal patterns)
  - **1 bar chart** comparing across operational dimensions (e.g., regions, warehouses, shifts, product categories)
  - **At least 1 slicer or filter** to make the dashboard interactive for diagnostic analysis
  - **Cross-filtering enabled** (if possible in your tool): clicking on one visual filters other visuals for drill-down analysis
  - Focus on diagnostic details that support action
  - Additional charts/visuals are welcome

#### Deliverables (DC ACT Framework)

**1. Define**

- **Stakeholder identification** (from Part 1.3): Who are you analyzing this for?
- **Problem statement** (from Part 1.4): What high-level problem does this stakeholder face?
  - Required format: "For [stakeholder name/title] at [company], they have [specific problem] which causes [business impact]."
  - **Scope**: Problem should be addressable through **descriptive and diagnostic analytics** (what happened and why)
  - Focus on operational performance issues that can be analyzed with historical data
  - Example: "For the Warehouse Operations Manager at LogisticsCo, they have inconsistent delivery times (ranging from 2-7 days) which causes customer complaints and lost repeat business."
  - **Good examples**: performance variability, process inefficiencies, quality issues, cost overruns, capacity problems
  - **Too narrow**: "We need to predict next month's sales" (that's Milestone 2 - Predictive)
  - **Too broad**: "We need to improve everything" (not specific or measurable)
- **Operations Management Decision Area** (from Part 1.2): Which of the 10 decision areas does this problem relate to?

**2. Collect**

- Original data file (before cleaning)
- Cleaned data file (after quality improvements)
- Data dictionary

**3. Analyze**

- **Excel workbook** (main deliverable) with:

  **Data Worksheets (Required):**

  - **Raw** tab: Original dataset loaded exactly as received (no modifications)
    - This is your source data - never modify this worksheet
    - Reference this data in your Prep worksheet
  - **Prep** tab: Analytics-ready cleaned dataset
    - All data cleaning and transformations applied here
    - This is the dataset used for all analysis and dashboards
    - You may use multiple worksheets and join them if needed, but keep raw data separate

  **Analysis Worksheets (Required):**

  - **Data_Dictionary** tab (column names, data types, and notes for all fields)
  - **Data_Cleaning_Log** tab (data quality assessment using framework from Part 2.4)
  - **Descriptive_Statistics** tab (statistical analysis of primary metric with central tendency & variability)
  - **Diagnostic_Pivot_Tables** tab (minimum 2 pivot tables analyzing categorical vs. numeric variables)
  - **Dashboard_Documentation** tab (required for both dashboards):
    - For each dashboard (Strategic and Operational), document:
      1. **Dashboard Name**: Strategic Dashboard or Operational Dashboard
      2. **Who is using this dashboard?** (specific role/title)
      3. **What decisions are being made with this dashboard?** (list 2-3 specific decisions)
    - Format as a simple table with 3 columns: Dashboard Name | User | Decisions
  - **Dashboard_Links** tab (if using external dashboards - include URLs with descriptions)
  - Additional analysis tabs (trend analysis, additional metrics as needed)
  - Dashboard tabs (if using Option 1: Excel dashboards - Strategic & Operational)
  - **IMPORTANT**: Excel workbook is for technical analysis only (calculations, tables, charts, dashboards)
  - **NO interpretation text boxes or cells in Excel** - all insights go in slide deck
- **Dashboard Requirements** (Strategic & Operational):

  - **Option 1**: Excel dashboards (within the same workbook as separate tabs)
  - **Option 2**: External tools (Tableau, Power BI, Looker Studio)
    - Must be **publicly accessible** (anyone with link can view)
    - Include dashboard URLs in the **Dashboard_Links** tab of your Excel workbook
    - Strategic Dashboard (Descriptive): High-level view of what happened
    - Operational Dashboard (Diagnostic): Detailed view for root cause analysis
  - **Required Components for EACH Dashboard** (regardless of tool):
    - **At least 2 scorecards** showing KPIs with comparisons
    - **1 line chart** showing trend over time
    - **1 bar chart** showing comparison across categories
    - **At least 1 slicer or filter** for interactivity
    - **Cross-filtering enabled** (if tool supports it)

**4. Communicate**

- **Slide Deck** (minimum 15 slides - THIS IS WHERE ALL INTERPRETATIONS LIVE):

  **Slide 1: Project Overview**

  - **Job description and company**: List the job title and company name
  - **Why I selected this job** (2 bullets):
    - What specific aspects of this role align with your career interests?
    - How does this position connect to your skills or experience?
  - **Stakeholder (name/title)**: Identify the specific person or role you're analyzing for
  - **Problem statement** in required format: "For [stakeholder], they have [problem] which causes [impact]."

  **Slide 2: Operations Management Decision Area**

  - **Decision Area Name** (in bold)
  - **2-3 sentence justification** explaining alignment with job responsibilities
    - Example: "**Supply Chain Management** - I selected Supply Chain Management as my decision area because the Supply Chain Analyst role at Amazon focuses on optimizing order fulfillment and delivery performance. The job description mentions analyzing delivery times, carrier performance, and distribution network efficiency—all core supply chain decisions."

  **Slide 3: Dataset Overview**

  - **Takeaway slide title** stating the value/relevance of the dataset (this IS the insight - not a label)
    - Example: "6 Months of Fulfillment Data Provides Sufficient History to Identify Delivery Patterns"
  - **Visual**: Table showing key dataset characteristics:
    - Data source (Custom GPT, Kaggle, company, public data, etc.)
    - Time period covered (e.g., "January 2025 - June 2025")
    - Number of records (e.g., "1,247 transactions")
    - Key variables (list 5-8 main columns: Order_ID, Order_Date, Delivery_Time, Region, etc.)
    - Granularity (daily, weekly, transaction-level, etc.)
  - **Two bullets below the visual**:
    - **Relevance**: How this dataset connects to the job description and problem statement
    - **Scope**: What operational aspects this data enables you to analyze

  **Slide 4: Data Quality Improvements**

  - **Takeaway slide title** stating the impact of data quality work (this IS the insight - not a label)
    - Example: "Cleaning 3 Critical Data Issues Ensures Accurate Analysis of Delivery Performance"
  - **Visual**: Table summarizing the top 3 data quality issues from your Data_Cleaning_Log:
    - Columns: Column Name | Issue Type | Records Affected | Decision
    - Example row: "Order_Date | Missing Values | 45 records (3%) | Removed"
  - **Two bullets below the visual**:
    - **Impact**: How cleaning these issues improves analysis reliability and prevents misleading conclusions
    - **Confidence**: Why the stakeholder can trust the insights that follow in subsequent slides

  **Slide 5: Primary Metric Definition**

  - **Takeaway slide title** stating why this metric matters (this IS the insight - not a label)
    - Example: "Delivery Time is the Key Metric Because It Directly Drives Customer Satisfaction and Repeat Business"
  - **Visual**: Display the metric name and definition in large, clear text (like a title card or definition box)
    - Include the unit of measurement (e.g., "Delivery Time in Days", "Order Quantity in Units", "Defect Rate as %")
  - **Two bullets below the visual**:
    - **Why it matters**: Explain the connection between this metric and the stakeholder's problem from the problem statement
    - **Decision support**: Describe how measuring this metric will help the stakeholder make better decisions
  - Note: This slide establishes the foundation for all analysis that follows - it answers "What are we measuring and why does it matter?"

  **Slide 6: Central Tendency Insight**

  - **Takeaway slide title** stating the insight (this IS the insight - not a label)
    - Example: "Typical Delivery Time is 4.2 Days (Median), Not 5.1 Days (Mean Skewed by Outliers)"
  - **Visual**: Display the selected measure and its value in large font (like a scorecard) OR screenshot of the statistics table from Excel
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take based on this central tendency?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?
  - Note: The slide title contains your insight about which measure is most appropriate and why

  **Slide 7: Variability Insight**

  - **Takeaway slide title** stating the insight (this IS the insight - not a label)
    - Example: "Delivery Times Vary Wildly (±2.8 Days), Creating Unpredictable Customer Experience"
  - **Visual**: Display the key variability measure in large font (like a scorecard) OR screenshot of histogram/statistics table from Excel
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take to address variability?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?
  - Note: The slide title contains your insight about what variability reveals about consistency/predictability

  **Slide 8: Diagnostic Pivot Table #1 Insight**

  - **Takeaway slide title** stating the root cause insight (this IS the insight - not a label)
    - Example: "East Region Accounts for 65% of Late Deliveries Due to Understaffing"
  - **Visual**: Screenshot of **ONE specific chart** from Pivot Table #1 (the chart that tells the key story)
  - **Two bullets below the visual**:
    - **Recommendation**: What specific action addresses this root cause?
    - **Prediction**: What improvement will result from this action?

  **Slide 9: Diagnostic Pivot Table #2 Insight**

  - **Takeaway slide title** stating the root cause insight (this IS the insight - not a label)
    - Example: "Morning Shift Has 2x Higher Defect Rate Than Afternoon Shift"
  - **Visual**: Screenshot of **ONE specific chart** from Pivot Table #2 (the chart that tells the key story)
  - **Two bullets below the visual**:
    - **Recommendation**: What specific action addresses this root cause?
    - **Prediction**: What improvement will result from this action?

  **Slide 10: Strategic Dashboard - Scorecard Insight**

  - **Takeaway slide title** stating the insight (this IS the insight - not a label)
    - Example: "Order Volume Up 35% YoY But Revenue Only Up 12%"
  - **Visual**: Screenshot of **ONE specific scorecard** from Strategic Dashboard
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take based on this?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?

  **Slide 11: Strategic Dashboard - Trend Insight**

  - **Takeaway slide title** stating the insight (this IS the insight - not a label)
    - Example: "Revenue Peaked in Q2 Then Declined 18% Despite Stable Order Volume"
  - **Visual**: Screenshot of **ONE specific line chart** from Strategic Dashboard showing trend over time
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take based on this trend?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?

  **Slide 12: Strategic Dashboard - Breakdown Insight**

  - **Takeaway slide title** stating the insight (this IS the insight - not a label)
    - Example: "West Region Drives 45% of Total Revenue Despite Having Only 28% of Orders"
  - **Visual**: Screenshot of **ONE specific bar or column chart** from Strategic Dashboard showing breakdown across categories
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take based on this breakdown?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?

  **Slide 13: Operational Dashboard - Scorecard Insight**

  - **Takeaway slide title** stating the diagnostic insight (this IS the insight - not a label)
    - Example: "Average Delivery Time 5.2 Days vs Target of 3 Days (73% Over Target)"
  - **Visual**: Screenshot of **ONE specific scorecard** from Operational Dashboard
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take to address this?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?

  **Slide 14: Operational Dashboard - Trend Insight**

  - **Takeaway slide title** stating the diagnostic insight (this IS the insight - not a label)
    - Example: "Delivery Times Spike Every Monday, Suggesting Weekend Backlog Issues"
  - **Visual**: Screenshot of **ONE specific line chart** from Operational Dashboard showing time-based diagnostic patterns
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take to address this pattern?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?

  **Slide 15: Operational Dashboard - Root Cause Breakdown Insight**

  - **Takeaway slide title** stating the root cause insight (this IS the insight - not a label)
    - Example: "East Region Accounts for 65% of Late Deliveries Due to Understaffing"
  - **Visual**: Screenshot of **ONE specific bar or column chart** from Operational Dashboard revealing root causes
  - **Two bullets below the visual**:
    - **Recommendation**: What action should the stakeholder take to address this root cause?
    - **Prediction**: If they follow this recommendation, what outcome can they expect?

  **Appendix Slide: Dashboard Links** (REQUIRED if using external dashboards)

  - **Title**: "Dashboard Links"
  - **Content**:
    - List each external dashboard with its publicly accessible URL
    - Include dashboard name and brief description
    - Example format:
      - **Strategic Dashboard**: [URL] - Executive-level view of key performance metrics
      - **Operational Dashboard**: [URL] - Detailed operational performance and root cause analysis
  - **CRITICAL**: Dashboard links must be publicly viewable from an incognito or private browser window (no login required)
  - **Note**: This slide is NOT required if both dashboards are built within your Excel workbook

  **Key Requirements**:

  - **Slide Title = The Insight**: Your title should state the finding, not describe the visual type (NOT "Strategic Dashboard" or "Central Tendency Analysis")
  - **ONE visual per slide**: No full dashboard screenshots - select the specific chart that tells the story
  - **Two bullets below visual**:
    1. Recommendation (what action to take)
    2. Prediction (what outcome to expect if they follow the recommendation)
  - **This is THE ONLY place for interpretations** - Excel contains NO text explanations

**5. Act**

Note: Your recommendations and predictions are already covered in each insight slide (Slides 5-15). This step ensures you've addressed:
- **Actionable recommendations**: Each slide has a specific action for the stakeholder (covered in your Recommendation bullets)
- **Expected outcomes**: Each slide predicts the result of following your recommendation (covered in your Prediction bullets)
- **Tracking metrics**: Consider mentioning in your predictions what metrics would show improvement (e.g., "Delivery time variance should decrease from ±2.8 days to ±1.5 days within 3 months")

#### Submission Files

Upload to Brightspace by **Monday, October 20, 2025, 8:00 AM**:

1. **`job-posting-fname-lname.pdf`** (your saved job description)

2. **`milestone-01-fname-lname.xlsx`** (MAIN DELIVERABLE - must include):
   - **Raw** worksheet (original dataset, unmodified)
   - **Prep** worksheet (cleaned, analytics-ready dataset)
   - **Data_Dictionary** worksheet (column names, data types, and notes)
   - **Data_Cleaning_Log** worksheet (data quality framework)
   - **Descriptive_Statistics** worksheet (primary metric analysis with central tendency & variability)
   - **Diagnostic_Pivot_Tables** worksheet (minimum 2 pivot tables with categorical/numeric analysis)
   - **Dashboard_Documentation** worksheet (who uses each dashboard and what decisions they make)
   - **Dashboard_Links** worksheet (if using external dashboards with public URLs)
   - Dashboard tabs for Strategic (Executive) and Operational dashboards (if using Excel)
   - Additional analysis tabs as needed

3. **`milestone-01-slides-fname-lname.pdf`** (minimum 15 slides, plus appendix slide if using external dashboards):
   - Slide 1: Project overview (job, why selected, stakeholder, problem statement)
   - Slide 2: Operations Management Decision Area with justification
   - Slide 3: Dataset Overview (data source, time period, records, key variables, relevance)
   - Slide 4: Data Quality Improvements (top 3 issues, impact, confidence)
   - Slide 5: Primary Metric Definition (why this metric matters and decision support)
   - Slide 6: Central Tendency insight (1 visual with Recommendation/Prediction bullets)
   - Slide 7: Variability insight (1 visual with Recommendation/Prediction bullets)
   - Slide 8: Diagnostic Pivot Table #1 insight (1 chart with Recommendation/Prediction bullets)
   - Slide 9: Diagnostic Pivot Table #2 insight (1 chart with Recommendation/Prediction bullets)
   - Slide 10: Strategic Dashboard - Scorecard insight (1 scorecard with Recommendation/Prediction bullets)
   - Slide 11: Strategic Dashboard - Trend insight (1 line chart with Recommendation/Prediction bullets)
   - Slide 12: Strategic Dashboard - Breakdown insight (1 bar/column chart with Recommendation/Prediction bullets)
   - Slide 13: Operational Dashboard - Scorecard insight (1 scorecard with Recommendation/Prediction bullets)
   - Slide 14: Operational Dashboard - Trend insight (1 line chart with Recommendation/Prediction bullets)
   - Slide 15: Operational Dashboard - Root Cause Breakdown insight (1 bar/column chart with Recommendation/Prediction bullets)
   - **Appendix**: Dashboard Links slide (REQUIRED if using Tableau, Power BI, Looker, or other external tools - must be publicly viewable from incognito/private browser)
   - **ONE visual per slide** with takeaway titles and two bullets below (Recommendation, Prediction)

**Notes**:

- **Excel workbook**: Technical analysis workspace only (calculations, tables, charts, dashboards) - NO interpretation text
- **Slide deck**: THE ONLY place for all insights, interpretations, and business implications
- Dashboard URLs must be publicly accessible (anyone with link can view) and included in Dashboard_Links tab
- For dashboards: screenshot ONE specific chart per slide that tells the key story (not full dashboard screenshots)

---

### Milestone 2: Predictive Analytics

**Due: Tuesday, November 11, 2025 by 11:59 PM**
**Weight: 15 points**

#### What You're Answering:

- **Predictive**: "What will happen?" - Forecasting and prediction

#### Project Continuity:

- **Same job and stakeholder** from Milestone 01
- **Flexible decision area** (can be same OR different from Milestone 01)
- **New problem** focused on predictive analytics (related to job/stakeholder)
- **New dataset** structured for time series forecasting and multiple linear regression
- **Clean data** - no Data_Cleaning_Log required (data will be ready for predictions)

#### Two Separate Predictive Analyses:

You will complete TWO distinct predictive analyses using the same dataset:

1. **Time Series Forecasting Analysis** - Forecast a metric over time (Problem A)
   - Test minimum 3 different forecasting models
   - Select 1 best model based on accuracy measures
   - Generate forecast for next period

2. **Multiple Linear Regression Analysis** - Predict an outcome based on drivers (Problem B - different from A)
   - Test minimum 3 different multiple regression models (each with at least 2 independent variables)
   - Select 1 best model based on fit and significance
   - Make predictions using selected model

**IMPORTANT: You MUST use Excel for all time series forecasting and regression analysis. Do not use Python, R, or other statistical software.**

#### Excel Analysis (REQUIRED):

**Time Series Forecasting:**
- Test minimum 3 models from:
  - N-Period Moving Average (e.g., 3-month, 6-month, etc.)
  - N-Period Weighted Moving Average
  - Excel's FORECAST.LINEAR (for trend projection)
  - Excel's FORECAST.ETS (for trend + seasonality)
- Calculate forecast accuracy for each model (MAD, MSE, and/or MAPE)
- Create comparison table showing all models with accuracy measures
- Select best method and justify choice
- Generate forecast for next period using best method

**Multiple Linear Regression:**
- Conduct correlation analysis to identify promising predictor variables
- Test minimum 3 multiple regression models:
  - Each model must have at least 2 independent variables
  - Test different combinations of variables (e.g., 2-variable model, 3-variable model, 4-variable model)
- Interpret key regression outputs:
  - Adjusted R² (model fit)
  - Coefficients (relationships between variables)
  - P-values (statistical significance)
  - Y-intercept (baseline prediction)
- Select best model and justify choice
- Make predictions for 2-3 scenarios using selected model
- Discuss business implications of relationships found

#### Deliverables (DC ACT Framework)

**1. Define**

- Connection to Milestone 01: Same job and stakeholder
- **Time Series Problem Statement**: What are you forecasting and why does it matter to stakeholder?
- **Regression Problem Statement**: What are you predicting and why does it matter to stakeholder?
- How do these predictions help stakeholder make better decisions?

**2. Collect**

- New dataset suitable for both time series forecasting and regression analysis
- Data dictionary for new dataset
- No Data_Cleaning_Log required (data is clean and ready)

**3. Analyze**

- Excel workbook with:
  - **Time_Series_Forecasting** tab:
    - Historical data plotted over time
    - Decomposition analysis (trend, seasonal, cyclic, random patterns)
    - Minimum 3 models tested with formulas visible
    - Accuracy comparison table (MAD, MSE, MAPE)
    - Selected forecast with next period prediction
  - **Regression_Analysis** tab:
    - Correlation matrix with conditional formatting
    - Minimum 3 multiple regression models (each with 2+ independent variables)
    - Model comparison table (Adjusted R², Standard Error, Significance F)
    - Selected model with coefficient interpretation
    - Scenario predictions (2-3 scenarios)
  - Clear labels, formulas visible, professional formatting
  - **Show your work**: Annotate what outputs mean

**4. Communicate**

- **Slide Deck** (11 slides - SEPARATE DECK, not attached to Milestone 01):

  **Slide 1: Milestone 02 Overview**
  - Job and stakeholder (reference from Milestone 01)
  - **Two predictive problems** you'll address:
    - **Time Series Problem**: [Brief statement - what you're forecasting]
    - **Regression Problem**: [Brief statement - what you're predicting]
  - How these predictions help stakeholder make better decisions
  - Connection to Milestone 01 (1 sentence): "Building on the [descriptive/diagnostic insights from M01], these forecasts enable proactive planning"

  **SECTION A: TIME SERIES FORECASTING (4 slides)**

  **Slide 2: Time Series Problem Statement**
  - Takeaway title stating what's being forecasted and why it matters to stakeholder
  - Visual: Line chart showing historical data of target variable over time
  - Two bullets:
    - **Problem**: What are we forecasting and why does it matter to stakeholder?
    - **Impact**: How does this forecast enable better decisions?

  **Slide 3: Time Series Decomposition and Pattern Identification**
  - Takeaway title identifying the patterns found (e.g., "Order Volume Shows Strong Seasonal Pattern with Upward Trend, No Cyclical Component")
  - Visual: Decomposition chart OR annotated line chart highlighting patterns:
    - Trend (long-term increase/decrease?)
    - Seasonal (regular up/down fluctuations?)
    - Cyclic (multi-year patterns?)
    - Random (erratic variation?)
  - Two bullets:
    - **Data**: Time period, granularity, number of observations (e.g., "24 months of weekly order data, 104 observations")
    - **Recommendation**: Which time series methods are appropriate given these patterns? (e.g., "Strong trend suggests FORECAST.LINEAR; seasonality suggests FORECAST.ETS")

  **Slide 4: Time Series Model Comparison**
  - Takeaway title announcing the winner (e.g., "FORECAST.ETS Achieves Lowest Error Rate at 8.2% MAPE, Outperforming Moving Average Methods")
  - Visual: Comparison table showing **minimum 3 models** with accuracy measures:
    - Model names (e.g., 3-Month MA, 6-Month MA, Weighted MA, FORECAST.LINEAR, FORECAST.ETS)
    - MAD, MSE, and/or MAPE for each
    - Highlight the best model
  - Two bullets:
    - **Recommendation**: Which model to use and why it's superior
    - **Justification**: What makes it better (accuracy, captures trend/seasonality, pattern fit)

  **Slide 5: Forecast Results**
  - Takeaway title with the forecast insight (e.g., "Demand Will Increase 18% Over Next Quarter, Requiring 25% Capacity Expansion")
  - Visual: Line chart showing historical actuals + forecast period
  - Two bullets:
    - **Recommendation**: What action should stakeholder take?
    - **Prediction**: What outcome if they follow recommendation?

  **SECTION B: REGRESSION ANALYSIS (6 slides)**

  **Slide 6: Regression Problem Statement**
  - Takeaway title stating what you're predicting and why it matters to stakeholder
  - Visual: Conceptual diagram OR simple visual showing the prediction challenge
  - Two bullets:
    - **Problem**: What are we predicting (dependent variable Y) and why does it matter to stakeholder?
    - **Impact**: How will understanding drivers of Y enable better decisions?

  **Slide 7: Regression Dataset Overview**
  - Takeaway title about the data characteristics (e.g., "1,500 Delivery Records Across 6 Months Provide Robust Sample for Driver Analysis")
  - Visual: Table or infographic showing dataset characteristics:
    - Data source
    - Time period or scope (e.g., "Q1-Q4 2024")
    - Number of observations (e.g., "1,500 delivery records")
    - Dependent variable (Y) being predicted
    - Number of potential independent variables available
  - Two bullets:
    - **Data**: Brief description of dataset scope and structure
    - **Variables**: What dependent variable (Y) will be predicted

  **Slide 8: Correlation Analysis**
  - Takeaway title revealing correlation insight (e.g., "Distance and Weight Show Strong Correlation with Delivery Time (r > 0.7)")
  - Visual: Correlation matrix with conditional formatting showing relationships between:
    - Dependent variable (Y)
    - Independent variables (X₁, X₂, X₃, etc.)
  - Two bullets:
    - **Variables**: Introduce the independent variables (X's) being tested (e.g., "Testing Distance, Weight, Carrier, Weather, Time of Day as potential drivers")
    - **Recommendation**: Which variables are promising predictors based on correlation strength?

  **Slide 9: Regression Model Comparison**
  - Takeaway title announcing winning model (e.g., "4-Variable Model Explains 82% of Delivery Time Variation (Best Balance of Fit and Significance)")
  - Visual: Model comparison table showing **minimum 3 multiple regression models** (each with at least 2 independent variables):
    - Model 1: 2 variables (e.g., Distance + Weight)
    - Model 2: 3 variables (e.g., Distance + Weight + Carrier)
    - Model 3: 4 variables (e.g., Distance + Weight + Carrier + Weather)
    - Key metrics: Adjusted R², Standard Error, Significance F
    - Highlight best model
  - Two bullets:
    - **Recommendation**: Which model to use and why
    - **Justification**: Why this model over others (accuracy, statistical significance, parsimony, all variables significant)

  **Slide 10: Key Drivers and Relationships**
  - Takeaway title revealing the insight (e.g., "Each Additional Mile Adds 0.12 Days to Delivery Time; Weather Has Minimal Impact (p > 0.05)")
  - Visual: Coefficient bar chart OR regression equation with coefficients and p-values
  - Two bullets:
    - **Recommendation**: Which factors should stakeholder manage/control?
    - **Interpretation**: What does a 1-unit change in X do to Y? (interpret the coefficients)

  **Slide 11: Prediction Scenarios**
  - Takeaway title with scenario insight (e.g., "Peak Season Scenario Predicts 6.2-Day Delivery, Exceeding 5-Day Target by 24%")
  - Visual: Table showing 2-3 scenarios with different input values and predicted outcomes
  - Two bullets:
    - **Recommendation**: How to use predictions for planning/decision-making
    - **Prediction**: Expected outcomes under each scenario

  **Key Requirements**:
  - **Slide Title = The Insight**: Your title should state the finding, not describe the visual type
  - **ONE visual per slide**: Select the specific chart/table that tells the story
  - **Two bullets below visual**:
    1. Recommendation (what action to take)
    2. Prediction (what outcome to expect) OR Justification/Interpretation (for analysis slides)
  - **Separate deck**: Do NOT attach to Milestone 01 slides

**5. Act**

- How should stakeholder use time series forecast? (covered in Slide 5)
- How should stakeholder use regression predictions? (covered in Slide 11)
- What decisions can be made with these forecasts?
- What are risks/limitations of predictions?
- How to monitor actual vs. predicted (track prediction accuracy)

#### Excel Workbook Requirements (REQUIRED - Must Use Excel)

You will submit **TWO separate Excel workbooks** (one for time series, one for regression) since you're solving two different predictive problems that may use different datasets. All analysis MUST be completed in Excel.

**Workbook 1: Time Series Forecasting Analysis**

File name: `milestone-02-time-series-fname-lname.xlsx`

Required worksheets:
1. **Raw** - Original time series dataset (unmodified)
2. **Prep** (optional) - Data cleaning/wrangling if needed
3. **Data_Dictionary** - Field definitions for time series dataset:
   - Column: Field name
   - Data Type: Text, number, date, etc.
   - Notes: Description and any important details
4. **Time_Series_Forecasting** - All time series analysis work:
   - Historical data with date/time column
   - Line chart showing target variable over time
   - Pattern decomposition analysis:
     - Trend component identified (increasing, decreasing, stable?)
     - Seasonal component identified (regular fluctuations?)
     - Cyclic component identified (multi-year patterns?)
     - Random component identified (irregular variations?)
   - Minimum 3 forecasting models tested:
     - N-Period Moving Average (show multiple period lengths)
     - N-Period Weighted Moving Average
     - Excel's FORECAST.LINEAR
     - Excel's FORECAST.ETS
   - Forecast accuracy calculations for each model:
     - MAD (Mean Absolute Deviation)
     - MSE (Mean Square Error)
     - MAPE (Mean Absolute Percentage Error)
   - Model comparison table showing all models with accuracy measures
   - Selected best model highlighted with justification
   - Forecast for next period using best model
   - All formulas visible and clearly labeled
   - Professional formatting with clear section headers

**Workbook 2: Multiple Linear Regression Analysis**

File name: `milestone-02-regression-fname-lname.xlsx`

Required worksheets:
1. **Raw** - Original regression dataset (unmodified)
2. **Prep** (optional) - Data cleaning/wrangling if needed
3. **Data_Dictionary** - Field definitions for regression dataset:
   - Column: Field name
   - Data Type: Text, number, date, etc.
   - Notes: Description and any important details
4. **Regression_Analysis** - All regression analysis work:
   - Dataset with dependent variable (Y) and independent variables (X₁, X₂, X₃, etc.)
   - Correlation matrix with conditional formatting:
     - Shows relationships between all variables
     - Color-coded by correlation strength
   - Minimum 3 multiple regression models tested:
     - Each model must have at least 2 independent variables
     - Test different combinations (e.g., 2-variable, 3-variable, 4-variable models)
   - Regression outputs for each model clearly labeled:
     - Adjusted R² (model fit)
     - Coefficients (slope for each variable)
     - P-values (statistical significance)
     - Standard Error
     - Significance F
     - Y-intercept
   - Model comparison table showing:
     - Model name/variables included
     - Adjusted R²
     - Standard Error
     - Significance F
     - Highlight best model
   - Selected best model with annotations explaining:
     - Why this model was chosen
     - Interpretation of coefficients (what 1-unit change in X does to Y)
     - Which variables are statistically significant (p < 0.05)
   - Scenario predictions table (2-3 scenarios):
     - Different input values for independent variables
     - Predicted outcome for each scenario
     - Show regression equation used
   - All formulas visible and clearly labeled
   - Professional formatting with clear section headers

**Key Requirements for Both Workbooks:**
- All formulas must be visible (not just results)
- Clear labels and annotations explaining what calculations mean
- Professional formatting with consistent styling
- Section headers to organize different parts of analysis
- Charts/tables properly titled
- No unnecessary worksheets or clutter

#### Submission Files

Upload to Brightspace by **Tuesday, November 11, 2025, 11:59 PM**:

1. **`milestone-02-time-series-fname-lname.xlsx`** (Time Series Forecasting Analysis - see Excel requirements above)
2. **`milestone-02-regression-fname-lname.xlsx`** (Multiple Linear Regression Analysis - see Excel requirements above)
3. **`milestone-02-slides-fname-lname.pdf`** (11 slides as specified above)

---

### Milestone 3: Prescriptive Analytics

**Due: Thursday, December 4, 2025 by 11:59 PM**
**Weight: 15 points**

**Detailed requirements for Milestone 3 will be released after Milestone 2 is completed.**

Key focus areas:

- **Linear Programming with Excel Solver**: Optimization modeling
- **Monte Carlo Simulation**: Risk analysis under uncertainty

---

## Part 4: Grading Rubrics

### Grading Breakdown per Milestone (100 points each)

Each milestone is graded out of **100 points** (which equals 15% of your final course grade).

**Grading Categories:**

- **Technical Execution**: 70 points (70%)
- **Presentation Clarity**: 30 points (30%)

**Technical Execution Breakdown (70 points):**

- Project Foundation & Data Quality: 13 points
- Technical Analysis Execution: 27 points
- Business Insights & Interpretation: 17 points
- Recommendations & Actions: 13 points

**Presentation Clarity Breakdown (30 points):**

- Slide design and visual quality: 10 points
- Takeaway titles and messaging: 10 points
- Professional communication: 10 points

---

### Milestone 1: Descriptive & Diagnostic Analytics Rubric (100 points)

#### Project Foundation & Data Quality (13 points)

- **13 - Excellent**:
  - **Problem Statement**: Clear, specific, follows required format exactly ("For [stakeholder], they have [problem] which causes [impact]"), meaningful business impact articulated
  - **Data_Dictionary**: Complete with all columns documented; includes column names, data types, and meaningful notes; professional table formatting
  - **Data_Cleaning_Log**: Complete with 3+ quality issues, all 7 columns filled thoroughly, framework applied properly, fixed critical issues appropriately, professional table formatting
  - **Dashboard_Documentation**: Both dashboards documented with specific users and 2-3 concrete decisions each
- **10 - Good**:
  - **Problem Statement**: Follows format, adequate specificity, business impact stated
  - **Data_Dictionary**: Most columns documented with data types and notes; adequate formatting
  - **Data_Cleaning_Log**: 2-3 issues, most columns completed adequately, framework applied reasonably, most issues fixed
  - **Dashboard_Documentation**: Both dashboards documented with users and decisions
- **7 - Adequate**:
  - **Problem Statement**: Present but vague or missing format elements
  - **Data_Dictionary**: Basic documentation present but missing some columns or notes; minimal formatting
  - **Data_Cleaning_Log**: Incomplete (1-2 issues or missing columns), framework partially applied
  - **Dashboard_Documentation**: Incomplete or generic
- **3 - Poor**:
  - **Problem Statement**: Vague, missing impact, doesn't follow format
  - **Data_Dictionary**: Severely incomplete or missing key information
  - **Data_Cleaning_Log**: Severely incomplete, framework not properly applied
  - **Dashboard_Documentation**: Missing or minimal
- **0 - Missing**: Problem statement OR Data_Dictionary OR Data_Cleaning_Log OR Dashboard_Documentation missing

#### Technical Analysis Execution (27 points)

- **27 - Excellent**:
  - **Descriptive_Statistics**: All central tendency measures (mean, median, mode) calculated correctly; variability measures (std dev, variance, range, CV) complete; histogram shows clear distribution; formulas visible; **NO interpretation text in Excel** (all insights in slides)
  - **Diagnostic_Pivot_Tables**: Minimum 2 pivot tables correctly constructed; each analyzes categorical variable against numeric metric; pivot charts, slicers, conditional formatting applied; professional formatting; **NO interpretation text in Excel** (all insights in slides)
  - **Dashboards**: Both dashboards meet ALL requirements (2+ scorecards, 1 line chart, 1 bar chart, 1+ slicer/filter, cross-filtering if possible); visuals are clear and insightful; appropriate detail level for each audience; professional design
  - Technical analysis reveals non-obvious patterns, professional formatting throughout
- **20 - Good**:
  - **Descriptive_Statistics**: Most measures calculated correctly; variability analysis present; histogram included; follows "no interpretation in Excel" rule
  - **Diagnostic_Pivot_Tables**: 2 pivot tables present with correct structure; good categorical/numeric analysis; most enhancements applied; follows "no interpretation in Excel" rule
  - **Dashboards**: Both dashboards meet minimum requirements (2+ scorecards, 1 line chart, 1 bar chart, 1+ filter); visuals adequate; reasonable audience differentiation; good formatting
  - Analysis shows expected patterns, good formatting
- **13 - Adequate**:
  - **Descriptive_Statistics**: Basic measures calculated, limited interpretation; some variability analysis; histogram present but basic
  - **Diagnostic_Pivot_Tables**: 1-2 pivot tables present but may have structural issues; limited interpretation; basic formatting
  - **Dashboards**: Dashboards mostly complete but missing 1-2 required components (e.g., only 1 scorecard, or missing filter); some visuals unclear; limited audience differentiation
  - Analysis is surface-level, acceptable formatting
- **7 - Poor**:
  - **Descriptive_Statistics**: Incomplete or incorrect calculations, minimal interpretation
  - **Diagnostic_Pivot_Tables**: Fewer than 2 pivot tables OR incorrect construction; minimal or no interpretation
  - **Dashboards**: Missing multiple required components (e.g., missing scorecards or charts); visuals unclear; no clear audience differentiation
  - Analysis is superficial or incorrect, poor formatting
- **0 - Missing**: No technical analysis or required worksheets (Descriptive_Statistics or Diagnostic_Pivot_Tables) missing

#### Business Insights & Interpretation (17 points)

- **17 - Excellent**:
  - All 13 insight slides present with structured format:
    - Slides 3-4: Dataset Overview and Data Quality
    - Slide 5: Primary Metric Definition
    - Slides 6-7: Central Tendency and Variability
    - Slides 8-9: 2 Pivot Tables
    - Slides 10-12: 3 Strategic Dashboard insights (scorecard, trend, breakdown)
    - Slides 13-15: 3 Operational Dashboard insights (scorecard, trend, breakdown)
  - Each follows **Insight → Recommendation → Prediction** format with specificity (except Slides 3-4 which follow the Dataset/Data Quality format)
  - Insights are business-relevant, actionable, reveal root causes, connect clearly to decision area
  - ONE visual per slide, screenshots focused on specific charts that tell the story
- **13 - Good**:
  - 11-12 insight slides present with structured format (Insight/Recommendation/Prediction)
  - Most insights are relevant and actionable, identify some root causes
  - One visual per slide, screenshots appropriate
- **10 - Adequate**:
  - 9-10 insight slides present, some follow structured format
  - Insights are somewhat generic, limited actionability, surface-level root cause analysis
  - May have multiple visuals per slide or full dashboard screenshots
- **7 - Poor**:
  - Fewer than 9 insight slides, format inconsistently applied
  - Insights are obvious or irrelevant, no clear root cause identification
- **0 - Missing**: No insights provided or severely inadequate (fewer than 8 slides)

#### Recommendations & Actions (13 points)

- **13 - Excellent**: Specific actions for stakeholder, clear implementation steps, metrics to track improvement
- **10 - Good**: Clear recommendations, general implementation guidance, some tracking metrics
- **7 - Adequate**: Generic recommendations, vague implementation, limited tracking
- **3 - Poor**: Obvious or irrelevant recommendations, no implementation guidance
- **0 - Missing**: No recommendations

#### Presentation Clarity (30 points)

- **30 - Excellent**:
  - **Minimum 15 slides present** (Slides 1-2 overview + Slides 3-15 insight slides)
  - **Slide 1-2**: Problem statement in exact required format with all elements (stakeholder, problem, impact, decision area with justification)
  - **Slide 3-4**: Dataset Overview and Data Quality slides with appropriate format (data characteristics and quality improvements)
  - **Insight slides (5-15)**: Each has compelling **takeaway title that IS the insight** (NOT descriptive labels like "Strategic Dashboard"), ONE focused visual, **two bullets below** (Recommendation, Prediction)
  - **Dashboard slides**: 3 insights per dashboard (scorecard, trend, breakdown) for both Strategic and Operational
  - Screenshots show **specific charts** from Excel/dashboards (not full dashboard screenshots)
  - Professional design throughout, polished communication, clear visual hierarchy
  - **NO interpretation in Excel workbook** - all insights in slides only
- **23 - Good**:
  - 13-14 slides present
  - Problem statement follows format with minor issues
  - Dataset and Data Quality slides present with good content
  - Most insight slides have takeaway titles that state insights, with two bullets below (Recommendation, Prediction)
  - Most dashboard insights present (may be missing 1-2)
  - Screenshots show specific visuals (may occasionally include full dashboard)
  - Good design, clear communication
  - Follows "no interpretation in Excel" rule
- **17 - Adequate**:
  - 11-12 slides present
  - Problem statement present but doesn't fully follow format
  - Dataset and/or Data Quality slides present but basic
  - Insight slides present but some titles are descriptive rather than takeaway-focused
  - Missing several dashboard insights
  - Screenshots included but may be unclear or full dashboards
  - Basic design, adequate communication
- **10 - Poor**:
  - Fewer than 11 slides
  - Problem statement vague or missing elements
  - Missing Dataset or Data Quality slides
  - Insight slides missing OR titles are purely descriptive, screenshots unclear
  - Most dashboard insights missing
  - Poor design, weak communication
  - May have interpretation text in Excel workbook (violates instructions)
- **0 - Missing**: No slides or severely inadequate presentation (fewer than 10 slides or missing problem statement)

---

### Milestone 2: Predictive Analytics Rubric (100 points)

#### Pre-Submission Checklist

Use this checklist to verify you have all required components before submitting:

**TIME SERIES EXCEL WORKBOOK (`milestone-02-time-series-fname-lname.xlsx`):**
- ☐ Raw worksheet with original time series dataset (unmodified)
- ☐ Data_Dictionary with all fields documented (column name, data type, notes)
- ☐ Time_Series_Forecasting worksheet with:
  - ☐ Historical data with date/time column
  - ☐ Line chart showing target variable over time
  - ☐ Pattern decomposition analysis (trend, seasonal, cyclic, random identified)
  - ☐ Minimum 3 forecasting models tested (from: MA, Weighted MA, FORECAST.LINEAR, FORECAST.ETS)
  - ☐ Error measures calculated for each model (MAD, MSE, MAPE)
  - ☐ Model comparison table with all models and accuracy measures
  - ☐ Best model highlighted with justification
  - ☐ Forecast for next period using best model
  - ☐ All formulas visible and clearly labeled
  - ☐ Professional formatting with section headers

**REGRESSION EXCEL WORKBOOK (`milestone-02-regression-fname-lname.xlsx`):**
- ☐ Raw worksheet with original regression dataset (unmodified)
- ☐ Data_Dictionary with all fields documented (column name, data type, notes)
- ☐ Regression_Analysis worksheet with:
  - ☐ Dataset with dependent variable (Y) and independent variables (X's)
  - ☐ Correlation matrix with conditional formatting (color-coded by strength)
  - ☐ Minimum 3 multiple regression models tested (each with 2+ independent variables)
  - ☐ Regression outputs for each model clearly labeled (Adjusted R², Coefficients, P-values, Standard Error, Significance F)
  - ☐ Model comparison table (model name/variables, Adjusted R², Standard Error, Significance F)
  - ☐ Best model highlighted with justification
  - ☐ Coefficient interpretation annotations (what 1-unit change in X does to Y)
  - ☐ Scenario predictions table (2-3 scenarios with different inputs)
  - ☐ All formulas visible and clearly labeled
  - ☐ Professional formatting with section headers

**SLIDE DECK (`milestone-02-slides-fname-lname.pdf`):**
- ☐ Total of 11 slides (separate deck, NOT attached to Milestone 01)
- ☐ Slide 1: Overview (job, stakeholder, two predictive problems, connection to M01)
- ☐ Slides 2-5: Time Series Analysis (problem, decomposition, model comparison, forecast results)
- ☐ Slides 6-11: Regression Analysis (problem, dataset, correlation, model comparison, drivers, scenarios)
- ☐ Every slide has a takeaway title that states the INSIGHT (not descriptive labels)
- ☐ Every slide has exactly ONE visual (focused chart/table, not full dashboards)
- ☐ Every slide has exactly two bullets below visual:
  - ☐ Recommendation (what action to take)
  - ☐ Prediction OR Justification/Interpretation
- ☐ Professional design and formatting throughout

---

#### Technical Execution (50 points)

**Time Series Analysis Execution (25 points)**

- **25 - Excellent**:
  - **Pattern Decomposition**: Thoroughly identifies all components (trend, seasonal, cyclic, random) with clear analysis of what patterns exist in the data
  - **Models Tested**: Minimum 3 models tested correctly with appropriate methods based on patterns identified; formulas visible and correct
  - **Accuracy Measures**: MAD, MSE, and MAPE calculated correctly for each model; comparison table shows all models with clear formatting
  - **Model Selection**: Best model selected with strong justification based on accuracy measures and pattern fit; reasoning is clear and evidence-based
  - **Forecast Generated**: Forecast for next period clearly shown using best model; forecast is reasonable given historical patterns
  - All work professionally organized with clear labels, section headers, and annotations explaining calculations

- **19 - Good**:
  - **Pattern Decomposition**: Identifies main components (trend, seasonal) with adequate analysis
  - **Models Tested**: 3 models tested correctly; formulas mostly visible; appropriate methods used
  - **Accuracy Measures**: MAD, MSE, MAPE calculated for each model; comparison table present with good formatting
  - **Model Selection**: Best model selected with reasonable justification based on accuracy
  - **Forecast Generated**: Forecast shown using best model; forecast is reasonable
  - Work is well-organized with labels and some annotations

- **13 - Adequate**:
  - **Pattern Decomposition**: Basic identification of patterns; limited analysis
  - **Models Tested**: 3 models tested but may have minor errors; some formulas visible
  - **Accuracy Measures**: Most accuracy measures calculated; comparison table present but basic
  - **Model Selection**: Model selected but justification is weak or generic
  - **Forecast Generated**: Forecast present but may be unclear
  - Work has basic organization and labels

- **6 - Poor**:
  - **Pattern Decomposition**: Incomplete or incorrect pattern identification
  - **Models Tested**: Fewer than 3 models OR significant errors in calculations
  - **Accuracy Measures**: Incomplete or incorrect error calculations
  - **Model Selection**: No clear justification for model choice
  - **Forecast Generated**: Missing or incorrect forecast
  - Work is poorly organized or unclear

- **0 - Missing**: Time series analysis missing or severely incomplete

**Regression Analysis Execution (25 points)**

- **25 - Excellent**:
  - **Correlation Matrix**: Complete correlation matrix with conditional formatting showing relationships between all variables; color-coded appropriately
  - **Models Tested**: Minimum 3 multiple regression models tested (each with 2+ independent variables); different variable combinations tested; all regression outputs clearly labeled
  - **Model Comparison**: Comparison table shows all models with key metrics (Adjusted R², Standard Error, Significance F); best model clearly highlighted
  - **Model Selection**: Best model selected with strong justification (accuracy, statistical significance, parsimony); explains why this model over others
  - **Coefficient Interpretation**: All coefficients interpreted correctly with clear annotations explaining what 1-unit change in X does to Y; identifies which variables are statistically significant (p < 0.05)
  - **Scenario Predictions**: 2-3 scenarios completed with different input values; predicted outcomes shown for each; regression equation visible
  - All work professionally organized with clear labels, section headers, and annotations

- **19 - Good**:
  - **Correlation Matrix**: Correlation matrix present with conditional formatting; shows key relationships
  - **Models Tested**: 3 multiple regression models tested correctly (2+ variables each); outputs labeled
  - **Model Comparison**: Comparison table present with key metrics; best model highlighted
  - **Model Selection**: Model selected with reasonable justification based on fit and significance
  - **Coefficient Interpretation**: Most coefficients interpreted correctly; identifies significant variables
  - **Scenario Predictions**: 2-3 scenarios completed; predictions shown
  - Work is well-organized with labels and annotations

- **13 - Adequate**:
  - **Correlation Matrix**: Basic correlation matrix present; limited formatting
  - **Models Tested**: 3 models tested but may have minor issues; some with fewer than 2 variables OR incomplete labeling
  - **Model Comparison**: Basic comparison table present
  - **Model Selection**: Model selected but weak justification
  - **Coefficient Interpretation**: Basic interpretation present; may miss some key elements
  - **Scenario Predictions**: 1-2 scenarios completed; predictions present but basic
  - Work has basic organization

- **6 - Poor**:
  - **Correlation Matrix**: Missing or poorly formatted
  - **Models Tested**: Fewer than 3 models OR models don't meet requirements (fewer than 2 variables)
  - **Model Comparison**: Incomplete or missing
  - **Model Selection**: No clear justification
  - **Coefficient Interpretation**: Incorrect or missing interpretations
  - **Scenario Predictions**: Missing or incorrect
  - Work is poorly organized

- **0 - Missing**: Regression analysis missing or severely incomplete

---

#### Presentation Clarity (50 points)

**Slide Design & Visual Quality (15 points)**

- **15 - Excellent**:
  - Every slide has exactly ONE focused visual (specific chart/table that tells the story)
  - Charts and tables are clear, easy to read, professionally formatted
  - Visuals are appropriately sized and positioned
  - Consistent design and layout throughout all 11 slides
  - Screenshots show specific charts from Excel, not full worksheets or dashboards
  - Visual hierarchy is clear (titles, visuals, bullets)

- **11 - Good**:
  - Most slides have one focused visual; occasional exceptions
  - Charts and tables are clear and readable
  - Good formatting with minor inconsistencies
  - Mostly consistent design
  - Most screenshots show specific visuals

- **8 - Adequate**:
  - Some slides have multiple visuals or unclear visuals
  - Charts/tables are readable but basic formatting
  - Some design inconsistencies
  - Some full worksheet/dashboard screenshots

- **4 - Poor**:
  - Multiple visuals per slide OR visuals are unclear
  - Charts/tables are difficult to read
  - Inconsistent or unprofessional design
  - Mostly full screenshots rather than focused visuals

- **0 - Missing**: No visuals or severely inadequate visual quality

**Takeaway Titles & Two-Bullet Format (20 points)**

- **20 - Excellent**:
  - All 11 slides present:
    - Slide 1: Overview
    - Slides 2-5: Time Series (problem, decomposition, comparison, results)
    - Slides 6-11: Regression (problem, dataset, correlation, comparison, drivers, scenarios)
  - Every slide title is a compelling **TAKEAWAY that states the insight** (e.g., "FORECAST.ETS Achieves Lowest Error Rate at 8.2% MAPE" NOT "Time Series Model Comparison")
  - Every slide has exactly **two bullets below the visual**:
    - First bullet: **Recommendation** (specific action to take)
    - Second bullet: **Prediction** (expected outcome) OR **Justification/Interpretation** (for analysis slides)
  - Bullets are specific, actionable, and business-relevant
  - Format is consistent across all slides

- **15 - Good**:
  - 10-11 slides present covering most required content
  - Most slide titles state insights; a few may be descriptive
  - Most slides follow two-bullet format (Recommendation + Prediction/Justification)
  - Bullets are mostly specific and relevant
  - Format is mostly consistent

- **10 - Adequate**:
  - 9-10 slides present; may be missing 1-2 required slides
  - Some slide titles are descriptive rather than insight-focused
  - Two-bullet format inconsistently applied
  - Bullets are somewhat generic or vague
  - Format varies across slides

- **5 - Poor**:
  - Fewer than 9 slides present; missing multiple required slides
  - Most titles are descriptive labels rather than insights
  - Two-bullet format rarely followed OR bullets are generic/irrelevant
  - Format is inconsistent

- **0 - Missing**: Severely inadequate presentation (fewer than 8 slides)

**Professional Polish & Completeness (15 points)**

- **15 - Excellent**:
  - **Excel Formulas**: All formulas visible in both workbooks (not just results)
  - **Labels & Annotations**: Clear labels throughout Excel; annotations explain what calculations mean and interpret key outputs
  - **Completeness**: No missing elements; all required components present in both workbooks and slides
  - **Organization**: Professional structure with section headers in Excel; logical flow in slides
  - **Formatting**: Consistent professional formatting; tables properly formatted; no clutter or unnecessary elements
  - **File Naming**: Correct file names used for all three submissions

- **11 - Good**:
  - Most formulas visible; a few may be hidden
  - Good labels and some annotations present
  - All major components present; may have minor omissions
  - Well-organized with clear structure
  - Good formatting with minor inconsistencies
  - File naming mostly correct

- **8 - Adequate**:
  - Some formulas visible but many hidden
  - Basic labels; limited annotations
  - Some required components missing
  - Basic organization; structure could be clearer
  - Adequate formatting but inconsistent
  - File naming partially correct

- **4 - Poor**:
  - Most formulas hidden
  - Minimal labels and annotations
  - Multiple missing components
  - Poor organization; unclear structure
  - Unprofessional or inconsistent formatting
  - Incorrect file naming

- **0 - Missing**: Severely incomplete or unprofessional work

---

## Part 5: Presentation & Communication Guidelines

### Slide Deck Requirements

**Cumulative Structure:**
Your slide deck grows throughout the semester as you add slides for each milestone:

1. **Project Overview** - Job description, stakeholder, decision area, problem statement
2. **Data Quality** - Key issues identified and their impact on analysis
3. **Descriptive Analytics** - What happened? Key trends and patterns
4. **Diagnostic Analytics** - Why did it happen? Root cause findings
5. **Predictive Analytics** - What will happen? Forecasts and model interpretation
6. **Prescriptive Analytics** - What should we do? Optimal solutions and risk assessment

---

### Takeaway Slide Titles (Critical!)

**What are takeaway titles?**
Takeaway titles communicate YOUR INSIGHT, not what the slide is about.

**❌ POOR Titles (Descriptive):**

- "Delivery Time Analysis"
- "Sales by Region"
- "Regression Results"
- "Simulation Output"

**✅ EXCELLENT Titles (Takeaway):**

- "Delivery Times Increased 40% in Q3 Due to Western Region Warehouse Delays"
- "Northeast Region Drives 60% of Revenue Despite Representing Only 30% of Customers"
- "Package Weight and Distance Explain 78% of Delivery Time Variation"
- "95% Probability of Stockout with Current Inventory Policy"

**Formula for Takeaway Titles:**
[Metric] + [Direction/Magnitude] + [Key Driver/Implication]

**Examples by Analytics Type:**

**Descriptive:**

> "Order Volume Grew 25% Year-Over-Year with December Peak at 2X Average"

**Diagnostic:**

> "Late Deliveries Concentrated in Weekend Orders from Warehouse B"

**Predictive:**

> "Demand Forecast Shows 15% Growth Next Quarter Driven by Seasonal Trends"

**Prescriptive:**

> "Optimal Product Mix Increases Profit by $45K Monthly Within Current Constraints"

---

### Visual Requirements

**Every slide needs a supporting visual:**

- **Charts**: Bar charts, line charts, scatter plots from Excel or Looker
- **Tables**: Formatted tables highlighting key numbers
- **Screenshots**: Dashboards from Looker, Solver solutions, simulation results
- **Diagrams**: Process flows, decision trees (if relevant)

**Chart Best Practices:**

- Clear axis labels with units
- Legends when needed
- Highlight key data points
- Remove chartjunk (unnecessary 3D effects, gridlines, etc.)
- Use consistent color scheme throughout deck

**Reference Tools:**

- Include links to Looker dashboards in appendix or notes
- Mention "See Excel file for detailed calculations"
- Don't make readers guess where analysis lives

---

### Professional Communication Standards

**What "Professional" Means:**

- ✅ Consistent formatting and fonts throughout deck
- ✅ No typos or grammatical errors
- ✅ Numbers formatted consistently (e.g., $1,234.56 not $1234.5600)
- ✅ Color scheme is readable and professional
- ✅ Slide numbers and deck title on every slide
- ✅ Logical flow from one slide to the next

**What to Avoid:**

- ❌ Walls of text (use bullet points, not paragraphs)
- ❌ Tiny font sizes (minimum 18pt for body text)
- ❌ Low-quality screenshots or images
- ❌ Inconsistent terminology (pick "stakeholder" or "client" and stick with it)
- ❌ Overly technical jargon without explanation

---

## Part 6: Interview Preparation

### Interview Format

**Midterm Interview (covers Milestone 1):**

- **When**: Week of October 20-22, 2025
- **Duration**: 20 minutes + 5 minutes debrief
- **Format**: Individual, one-on-one with professor
- **Opening**: "Tell me about your project"
- **Coverage**: Data quality, descriptive analytics, diagnostic analytics

**Final Interview (covers Milestones 2-3):**

- **When**: Finals week, December 2025
- **Duration**: 20 minutes + 5 minutes debrief
- **Format**: Individual, one-on-one with professor
- **Opening**: "Tell me about your project"
- **Coverage**: Predictive analytics, prescriptive analytics, synthesis across all types

**What to Bring:**

- You do NOT need to walk through slides
- You should have your slides submitted beforehand
- Be prepared to recreate a sketch of visualizations using the whiteboard

---

### Interview Assessment Criteria

The interview assesses different dimensions than the milestone submissions:

**Milestone Submission** = Deliverables, documentation, technical accuracy  
**Interview** = Understanding, synthesis, communication under pressure

**How You Are Evaluated:**

1. **Depth of Understanding** (40%)

   - Can you explain WHY you made analytical choices?
   - Do you understand what your numbers mean?
   - Can you defend your methodology?
2. **Business Acumen** (30%)

   - Do you connect analysis to business problems?
   - Are your recommendations realistic and actionable?
   - Do you understand your stakeholder's perspective?
3. **Communication Skills** (20%)

   - Can you explain technical concepts clearly?
   - Do you structure responses logically?
   - Can you adapt to follow-up questions?
4. **Synthesis & Progression** (10%)

   - Do you see connections across analytics types?
   - Can you articulate the analytics maturity journey?
   - Do insights build on each other?

---

### Common Interview Questions

**Project Foundation:**

- "Tell me about your project." (2-3 minute opening)
- "Why did you choose this job/company/stakeholder?"
- "How does your problem connect to [Decision Area]?"

**Data Quality:**

- "What data quality issues did you find?"
- "Walk me through how you applied the Data Quality Framework for [specific issue]."
- "Why did you choose to [fix/not fix] [specific issue]?"

**Descriptive Analytics:**

- "What were the key trends you discovered?"
- "What surprised you in the data?"
- "How did you decide which metrics to focus on?"

**Diagnostic Analytics:**

- "What was the root cause of [problem]?"
- "How did you use pivot tables/slicers to drill down?"
- "Were there any root causes you expected to find but didn't?"

**Predictive Analytics:**

- "Why did [forecasting method] work better than [other method]?"
- "Explain what the regression coefficients tell you."
- "What does an adjusted R² of [X] mean?"
- "How confident are you in your forecast? What could go wrong?"

**Prescriptive Analytics:**

- "Walk me through your optimization model."
- "What are the key constraints and why do they matter?"
- "What does the sensitivity analysis tell you?"
- "Explain the probability distribution from your simulation."
- "What level of risk is acceptable and why?"

**Synthesis:**

- "How did your descriptive findings inform your predictive model?"
- "Looking across all four analytics types, what's the story?"
- "If your stakeholder could only implement ONE recommendation, which would you prioritize?"

**Challenge Questions:**

- "What would you do differently if you started over?"
- "What are the limitations of your analysis?"
- "How would you validate your recommendations?"

---

### How to Prepare for Interviews

**1. Practice Your Opening (2-3 minutes)**
Structure: Job/Company → Stakeholder → Problem → Decision Area → Brief preview of findings

Example:

> "I analyzed order fulfillment operations for a Supply Chain Analyst role at ShopNow, an e-commerce company. My stakeholder is the Fulfillment Operations Manager who is facing increasing delivery times—currently 5.2 days versus a 3-day target. This connects to the Supply Chain Management decision area because it involves optimizing how products reach customers. Through my analysis, I discovered that the root cause is warehouse location inefficiencies, predicted delivery times will continue increasing without intervention, and developed an optimization model to reduce costs by 20% while meeting delivery targets."

**2. Review Your Own Work Thoroughly**

- Re-read your slides and analysis 2-3 days before interview
- Make sure you can explain every chart, every formula, every insight
- Practice explaining technical concepts in simple terms
- Review the DC ACT Framework and be ready to map your work to it

**3. Anticipate Follow-Up Questions**
For every insight you present, ask yourself:

- "How do I know this is true?" (evidence)
- "Why does this matter?" (business impact)
- "What should we do about it?" (action)

**4. Practice Verbally**

- Record yourself answering "Tell me about your project"
- Practice with a friend or family member
- Time yourself—can you explain your key findings in 2-3 minutes?

**5. Prepare Examples**
Have specific examples ready:

- "For example, I found that Warehouse B had 40% longer delivery times..."
- "To illustrate, when I increased the budget constraint by 10%, profit increased by..."

**6. Be Honest About Limitations**
If asked something you don't know:

> "That's a great question. I didn't analyze [that specific aspect], but if I were to explore it, I would..."

---

### STAR Method for Behavioral Responses

When answering "how" or "why" questions, use STAR structure:

**S**ituation: "The problem was..."
**T**ask: "I needed to..."
**A**ction: "I approached this by..."
**R**esult: "This revealed that..."

Example:

> **S**: "The delivery time data showed increasing trends, but I didn't know why."
> **T**: "I needed to identify which factors were driving the delays."
> **A**: "I used pivot tables with slicers to break down delivery times by warehouse location, carrier, product category, and day of week."
> **R**: "This revealed that Warehouse B had consistently longer delivery times across all categories, pointing to a location-specific issue rather than a carrier or product problem."

---

## Part 7: Common Pitfalls & How to Avoid Them

### Pitfall #1: "I Can't Find Relevant Data"

**Why This Happens:**

- Problem statement is too specific or too vague
- Looking for perfect data instead of workable data
- Not using the Custom GPT effectively

**How to Avoid:**

- Start with Custom GPT—it's designed to generate exactly what you need
- Broaden your problem slightly if needed (inventory → supply chain)
- Focus on data that supports your decision area, not perfect match
- Schedule office hours EARLY if you're stuck

---

### Pitfall #2: "My Project Is Too Complicated"

**Why This Happens:**

- Trying to analyze everything instead of one focused problem
- Adding features you think will impress rather than meet requirements
- Confusing complexity with quality

**How to Avoid:**

- Start simple and build incrementally
- Focus on ONE problem statement, not multiple problems
- Meet minimum requirements first, THEN add sophistication
- Remember: Clear and correct > complicated and confusing

**Complexity Checkpoints:**

- Descriptive/Diagnostic: 1 problem, 5-8 metrics, 2-3 dimensions
- Predictive: 1 target variable, 3-8 independent variables
- Prescriptive: 3-6 decision variables, 4-6 constraints

---

### Pitfall #3: "I Don't Clearly Know My Stakeholder/Problem"

**Why This Happens:**

- Rushing into data collection before foundation is set
- Choosing a generic problem instead of specific scenario
- Not connecting to job description

**How to Avoid:**

- Complete Project Kickoff Checklist (Part 1.5)
- Test your problem statement: Can someone else understand what the stakeholder needs?
- Use LinkedIn research to make stakeholder feel real
- Get feedback on your problem statement in office hours

---

### Pitfall #4: "My Analysis Is Technically Correct but Lacks Business Insight"

**Why This Happens:**

- Focusing only on technical execution without interpretation
- Not asking "so what?" after every finding
- Treating this as a math exercise instead of business problem-solving

**How to Avoid:**

- After every analysis step, write: "This means that..."
- Connect every insight to your stakeholder's problem
- Ask yourself: "If I were the stakeholder, what would I do with this information?"
- Use takeaway slide titles—forces you to articulate insights

---

### Pitfall #5: "My Slides Are Full of Analysis but Don't Tell a Story"

**Why This Happens:**

- Dumping every analysis into slides
- Organizing by technique instead of by insight
- Not using takeaway titles

**How to Avoid:**

- Start with takeaway titles BEFORE creating slides
- Select only the most important 3-5 insights per analytics type
- Each slide should answer: "What did I learn and why does it matter?"
- Less is more—cut anything that doesn't support your recommendations

---

## Part 8: Frequently Asked Questions (FAQ)

### General

**Q: Can I work with a partner or group?**
A: No. This project must be completed individually. The goal is for you to own this work completely so you can discuss it confidently in job interviews.

**Q: Can I use the same dataset for all three milestones?**
A: You MUST use the same dataset for Descriptive + Diagnostic. You MAY use different datasets for Predictive and Prescriptive if your original dataset doesn't support those analyses. However, simpler is often better—try to use the same dataset throughout if possible.

**Q: What if I find a great job posting but it gets removed before the deadline?**
A: This is why you save it as a PDF immediately. The saved PDF is what you'll submit.

**Q: My job description doesn't explicitly mention data or analytics. Is that okay?**
A: Yes! Almost every operations role involves data-driven decision-making even if not explicitly stated. Focus on the operational challenges the role addresses and how data could help solve them.

---

### Data Collection

**Q: What if the Custom GPT doesn't generate exactly what I need?**
A: The GPT asks you questions to customize data. If it's not quite right, you can iterate by providing more specific requirements. You can also bring your own data if you find a better source.

**Q: Can I use data from my internship or job?**
A: Yes, IF you have explicit permission and anonymize any sensitive information. Save the permission email and include it with your submission.

**Q: How do I know if my dataset is "good enough"?**
A: Minimum requirements: 500 rows, 5+ variables, relevant to your problem, includes data quality issues to fix. If you meet these, you're good. Quality > quantity.

**Q: What if my data doesn't have quality issues?**
A: Real data always has quality issues. Look harder. If it's truly perfect (unlikely), you must artificially introduce issues for the learning exercise. Data quality assessment is a required competency.

---

### Technical Analysis

**Q: I've never used Looker Studio. How do I start?**
A: See the Looker Studio tutorial in Brightspace. Start with connecting your data source, then add charts one at a time. Office hours can help troubleshoot.

**Q: Excel Solver isn't finding a solution. What do I do?**
A: Common issues: (1) Constraints are impossible (too restrictive), (2) Formulas have errors, (3) Solver settings need adjustment. See Solver troubleshooting guide in Brightspace or visit office hours.

**Q: My R² is only 0.45. Is that bad?**
A: Not necessarily! R² depends on your data and problem. Discuss what this means for your business application. "Low" R² might still provide valuable insights. What matters is interpretation, not hitting a specific number.

**Q: How many simulation runs should I do?**
A: Minimum 1,000. Recommended 5,000-10,000. More runs = more stable results. Stop when adding runs doesn't change your conclusions.

---

### Slides & Communication

**Q: Can I have more than 5 slides per analytics type?**
A: Yes, but be strategic. More slides doesn't always mean better communication. If you have genuinely important insights that need 6-7 slides, that's fine. But avoid padding.

**Q: Do I need to include my Excel workbook screenshots in slides?**
A: Include visuals that support your insights. This could be charts from Excel, dashboard screenshots from Looker, or tables showing key results. Don't just paste raw Excel screenshots—extract the insight.

**Q: What if I can't think of a good takeaway title?**
A: Start with your data → insight → takeaway formula:

1. What does the data show? "Delivery times increased by 40%"
2. What caused it? "Western region warehouse"
3. Combine: "Delivery Times Increased 40% Due to Western Region Warehouse Issues"

**Q: Should I include an appendix with detailed calculations?**
A: You can, but it's not required. Your Excel workbook is your detailed documentation. Slides should communicate insights, not show every calculation.

---

### Interviews

**Q: Will you ask me to explain specific formulas or calculations?**
A: Possibly. You should understand how your analysis works, not just what the output says. Example: "Explain how exponential smoothing works" or "What does this coefficient mean?"

**Q: What if I get a question I can't answer?**
A: Be honest. Say "I don't know, but here's how I would figure it out..." or "I didn't analyze that aspect, but if I did..." Intellectual honesty is valued.

**Q: Can I reference my slides or Excel during the interview?**
A: No. You should know your project well enough to respond to questions accurately without referencing your materials.

**Q: How much should I talk vs. wait for questions?**
A: Open with 2-3 minute overview, then the interview becomes conversational. I'll ask questions, you answer, I'll probe deeper. It's a dialogue, not a presentation.

---

### Grading & Deadlines

**Q: What if I miss a milestone deadline?**
A: There is a 10% penalty for every day that the submission is late. Plan ahead and communicate if you have extenuating circumstances.

**Q: If I do poorly on Milestone 1, can I still get an A on the project?**
A: Yes. Each milestone is independently graded. Learn from feedback and improve in subsequent milestones.

**Q: How much weight is the interview vs. the submission?**
A: Interview is separate from project milestones. Milestone submissions = 45 points total (15 each). Interviews = 40 points total (Midterm 15, Final 25). Both matter significantly.

**Q: Will you provide feedback between milestones?**
A: Yes. Feedback on Milestone 1 will be provided before Milestone 2 is due. Use this feedback to improve.

---

## Conclusion

This project is your opportunity to demonstrate **end-to-end analytics capability**—from defining a business problem, to collecting and cleaning data, to applying sophisticated analytical techniques, to communicating actionable insights.

**Key Takeaways:**

1. **Foundation First**: Spend time in Weeks 3-4 getting your job, stakeholder, and problem right
2. **Use Frameworks**: DC ACT, Data Quality Framework, and 10 Decision Areas guide your work
3. **Focus on Insights**: Technical correctness is necessary but not sufficient—interpret what it means
4. **Communicate Clearly**: Takeaway titles, supporting visuals, professional polish
5. **Prepare for Interviews**: Practice explaining your work—you'll need this skill in job interviews

**This project is worth 45% of your grade, but more importantly, it's a career asset you'll reference for years.**

Good luck! Use office hours. Start early. Make it something you're proud to show future employers.

---

## Appendix: Quick Reference

### Project Timeline Overview

- **Milestone 1**: Due Monday, October 20, 2025
- **Milestone 2**: Due Tuesday, November 11, 2025
- **Milestone 3**: Due Thursday, December 4, 2025
- **Midterm Interviews**: Week 7
- **Final Interviews**: Finals Week

### Submission Checklist Template

**Milestone 1:**

- [ ] **job-posting-fname-lname.pdf** (your saved job description)
- [ ] **milestone-01-fname-lname.xlsx** (MAIN DELIVERABLE) with:
  - [ ] **Raw** worksheet (original unmodified data)
  - [ ] **Prep** worksheet (cleaned analytics-ready data)
  - [ ] **Data_Dictionary** worksheet (column names, data types, notes)
  - [ ] **Data_Cleaning_Log** worksheet (data quality framework)
  - [ ] **Descriptive_Statistics** worksheet (central tendency & variability analysis)
  - [ ] **Diagnostic_Pivot_Tables** worksheet (minimum 2 pivot tables)
  - [ ] **Dashboard_Documentation** worksheet (users and decisions for each dashboard)
  - [ ] **Dashboard_Links** worksheet (if using external dashboards)
  - [ ] Strategic Dashboard with 2+ scorecards, 1 line chart, 1 bar chart, 1+ filter
  - [ ] Operational Dashboard with 2+ scorecards, 1 line chart, 1 bar chart, 1+ filter
  - [ ] Additional analysis tabs as needed
- [ ] **milestone-01-slides-fname-lname.pdf** (minimum 15 slides, plus appendix if using external dashboards):
  - [ ] Slide 1: Project overview (job, why selected, stakeholder, problem statement)
  - [ ] Slide 2: Operations Management Decision Area with justification
  - [ ] Slide 3: Dataset Overview (data source, time period, records, key variables, relevance)
  - [ ] Slide 4: Data Quality Improvements (top 3 issues, impact, confidence)
  - [ ] Slide 5: Primary Metric Definition (why this metric matters)
  - [ ] Slide 6: Central Tendency insight with Recommendation/Prediction
  - [ ] Slide 7: Variability insight with Recommendation/Prediction
  - [ ] Slide 8: Diagnostic Pivot Table #1 insight with Recommendation/Prediction
  - [ ] Slide 9: Diagnostic Pivot Table #2 insight with Recommendation/Prediction
  - [ ] Slide 10: Strategic Dashboard - Scorecard insight with Recommendation/Prediction
  - [ ] Slide 11: Strategic Dashboard - Trend insight with Recommendation/Prediction
  - [ ] Slide 12: Strategic Dashboard - Breakdown insight with Recommendation/Prediction
  - [ ] Slide 13: Operational Dashboard - Scorecard insight with Recommendation/Prediction
  - [ ] Slide 14: Operational Dashboard - Trend insight with Recommendation/Prediction
  - [ ] Slide 15: Operational Dashboard - Root Cause Breakdown insight with Recommendation/Prediction
  - [ ] Appendix: Dashboard Links slide (if using external dashboards - must be publicly viewable from incognito/private browser)

**Milestone 2:**

- [ ] **milestone-02-fname-lname.xlsx** (Excel Analysis Workbook with forecasting + regression)
- [ ] **milestone-02-slides-fname-lname.pdf**
- [ ] Data files if using new dataset (include Data_Cleaning_Log if new)

**Milestone 3:**

- [ ] **milestone-03-fname-lname.xlsx** (Excel Analysis Workbook with optimization + simulation)
- [ ] **milestone-03-slides-fname-lname.pdf**
- [ ] Data files if using new dataset (include Data_Cleaning_Log if new)

### File Naming Convention

All files use lowercase kebab-case with `fname-lname`:

- `job-posting-fname-lname.pdf`
- `milestone-01-fname-lname.xlsx`
- `milestone-01-slides-fname-lname.pdf`
- `milestone-02-fname-lname.xlsx`
- `milestone-02-slides-fname-lname.pdf`
- `milestone-03-fname-lname.xlsx`
- `milestone-03-slides-fname-lname.pdf`

Replace `fname` with your first name and `lname` with your last name (e.g., `milestone-01-john-smith.xlsx`)

---

**Document Version**: 1.0
**Last Updated**: September 30, 2025
**Questions?** Send a Teams message or schedule office hours on https://calendly.com/greg-lontok
